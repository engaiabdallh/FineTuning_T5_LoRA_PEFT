{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rwM15bpoFqWI"
      },
      "source": [
        "### `Hands-On`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TEvqE3oWDchD",
        "outputId": "a832fc63-ec47-4d84-879a-d7a547c7530e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers==4.55.2 in /usr/local/lib/python3.11/dist-packages (4.55.2)\n",
            "Requirement already satisfied: datasets==4.0.0 in /usr/local/lib/python3.11/dist-packages (4.0.0)\n",
            "Collecting evaluate==0.4.5\n",
            "  Downloading evaluate-0.4.5-py3-none-any.whl.metadata (9.5 kB)\n",
            "Collecting rouge-score==0.1.2\n",
            "  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting loralib==0.1.2\n",
            "  Downloading loralib-0.1.2-py3-none-any.whl.metadata (15 kB)\n",
            "Requirement already satisfied: peft==0.17.0 in /usr/local/lib/python3.11/dist-packages (0.17.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers==4.55.2) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.11/dist-packages (from transformers==4.55.2) (0.34.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers==4.55.2) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers==4.55.2) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers==4.55.2) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers==4.55.2) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers==4.55.2) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers==4.55.2) (0.21.4)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers==4.55.2) (0.6.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers==4.55.2) (4.67.1)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets==4.0.0) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets==4.0.0) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets==4.0.0) (2.2.2)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets==4.0.0) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets==4.0.0) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets==4.0.0) (2025.3.0)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.11/dist-packages (from rouge-score==0.1.2) (1.4.0)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (from rouge-score==0.1.2) (3.9.1)\n",
            "Requirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.11/dist-packages (from rouge-score==0.1.2) (1.17.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from peft==0.17.0) (5.9.5)\n",
            "Requirement already satisfied: torch>=1.13.0 in /usr/local/lib/python3.11/dist-packages (from peft==0.17.0) (2.6.0+cu124)\n",
            "Requirement already satisfied: accelerate>=0.21.0 in /usr/local/lib/python3.11/dist-packages (from peft==0.17.0) (1.10.0)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets==4.0.0) (3.12.15)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers==4.55.2) (4.14.1)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers==4.55.2) (1.1.7)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.55.2) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.55.2) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.55.2) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.55.2) (2025.8.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft==0.17.0) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft==0.17.0) (3.1.6)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=1.13.0->peft==0.17.0)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=1.13.0->peft==0.17.0)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=1.13.0->peft==0.17.0)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=1.13.0->peft==0.17.0)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=1.13.0->peft==0.17.0)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=1.13.0->peft==0.17.0)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=1.13.0->peft==0.17.0)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=1.13.0->peft==0.17.0)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=1.13.0->peft==0.17.0)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft==0.17.0) (0.6.2)\n",
            "Collecting nvidia-nccl-cu12==2.21.5 (from torch>=1.13.0->peft==0.17.0)\n",
            "  Downloading nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft==0.17.0) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=1.13.0->peft==0.17.0)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft==0.17.0) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft==0.17.0) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.13.0->peft==0.17.0) (1.3.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk->rouge-score==0.1.2) (8.2.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk->rouge-score==0.1.2) (1.5.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets==4.0.0) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets==4.0.0) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets==4.0.0) (2025.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets==4.0.0) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets==4.0.0) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets==4.0.0) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets==4.0.0) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets==4.0.0) (6.6.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets==4.0.0) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets==4.0.0) (1.20.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.13.0->peft==0.17.0) (3.0.2)\n",
            "Downloading evaluate-0.4.5-py3-none-any.whl (84 kB)\n",
            "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading loralib-0.1.2-py3-none-any.whl (10 kB)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m50.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m56.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m50.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m13.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl (188.7 MB)\n",
            "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m188.7/188.7 MB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m53.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: rouge-score\n",
            "  Building wheel for rouge-score (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for rouge-score: filename=rouge_score-0.1.2-py3-none-any.whl size=24934 sha256=17ce31b02668d17b95faf8bd510cea1caa6c7e7289b5853c5dfb0272af3ed45b\n",
            "  Stored in directory: /root/.cache/pip/wheels/1e/19/43/8a442dc83660ca25e163e1bd1f89919284ab0d0c1475475148\n",
            "Successfully built rouge-score\n",
            "Installing collected packages: nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, loralib, rouge-score, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, evaluate\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-nccl-cu12\n",
            "    Found existing installation: nvidia-nccl-cu12 2.23.4\n",
            "    Uninstalling nvidia-nccl-cu12-2.23.4:\n",
            "      Successfully uninstalled nvidia-nccl-cu12-2.23.4\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed evaluate-0.4.5 loralib-0.1.2 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nccl-cu12-2.21.5 nvidia-nvjitlink-cu12-12.4.127 rouge-score-0.1.2\n"
          ]
        }
      ],
      "source": [
        "!pip install -U \\\n",
        " transformers==4.55.2 \\\n",
        " datasets==4.0.0 \\\n",
        " evaluate==0.4.5 \\\n",
        " rouge-score==0.1.2 \\\n",
        " loralib==0.1.2 \\\n",
        " peft==0.17.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "TxGBFRkBGEWy"
      },
      "outputs": [],
      "source": [
        "# Load model directly\n",
        "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, TrainingArguments, Trainer\n",
        "from datasets import load_dataset\n",
        "import torch\n",
        "from peft import LoraConfig, get_peft_model, TaskType, PeftModel, PeftConfig\n",
        "from huggingface_hub import notebook_login\n",
        "from evaluate import load\n",
        "from transformers import GenerationConfig"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 370,
          "referenced_widgets": [
            "93a57f9e4dec4d85a4cb125bf0576127",
            "d6ca99211b824100b6edc7ef508002b2",
            "83430c30681143499eeee8f032e02e13",
            "dc1377ffe26a417198e001f1e3cb198a",
            "d9488ae7078148d48cf15272d185b2b2",
            "fa2503cf8b914b19929db1941404090e",
            "3755e7d6096e491c88ef829b31069a38",
            "4f42ffb450f3411c95cd51c2bd2d63a6",
            "cd654d24367e4b57bb4dda9c9aa92332",
            "77f82d12ae67436ab8b88a36cdca861d",
            "a7fb433d936646a4a040586c324c70a7",
            "45be4ecc0f79450abdda20a8385d1e27",
            "fa949920af1e47d18bf2a3c088e135f4",
            "828104f040354b7e8176a79cac4f2380",
            "0289cb37f9e5491da7b0cd8aec3a4a3c",
            "fb28ad152fb94576a536d4d607fc58c5",
            "e996a935fc954f40bace6981bce436ff",
            "3b567acfb14a465fa73919cf5f21dbcd",
            "9878f2b342444ef0b82fccf9e6b5dbab",
            "9238a11487534b8886b2e05948a530f5",
            "98f065daf2c346f1a63f138c31d91831",
            "3530662761a84fbb939612b107be8d0f",
            "d86b1a831ed7487f9b744d912ea6f59f",
            "ad49524dd2284a1899e4f58a10629a3e",
            "ebea7d70208f4935989c1fce5da44698",
            "0776dfd8ee864da9afa1f1c77e1606ba",
            "de1759729b8f4f529868de1cf6e74991",
            "a2122c3a50cd478a80aa2e6d82c39845",
            "4b63d952cb874fe284c652890273112a",
            "952a16c9716442429c0b1ff04f57aed6",
            "9d0162f2d3374191a7152cc8d16ba9ca",
            "67caf84a1ed3456fa709a9e07520f50d",
            "7615a4111e5144faaf435725404cb1b4",
            "5197bc8b931648fcb53e79868bc5f359",
            "697e912562aa4c99b0d0dbe27576186f",
            "05a3375f4b6d418b9389794c1fb4d05e",
            "3502ad610bb447e78f5edaa0215ef2f8",
            "dae11b89b61346e99b12bf988e01e42e",
            "0bd0214a119e4c90a46e7aa653da1870",
            "c6d94a2f22de48d9ba4f150b0fe6f732",
            "7c03fe5df0cd4ce6a72bd58cec6fe5d3",
            "6d0eab5aa20d42c6b530d68c80304b8b",
            "24b50b61bd984ce888704f24b3602cb0",
            "b33709255e2b444b9dddb9c31c07aa90",
            "1afe0bd24ca2465491962aca4c7ba705",
            "5aff662b73cd41ebb91d530a98e15446",
            "6dba518f4fb24fbb81db198cf8b06ec8",
            "6f749004132e4199a125d379f0f6f2fd",
            "c083de8179854f9c85893cbbca49528a",
            "096de9a04d7c467d8e047695e51a7d5b",
            "f274e3b47b0b4171bb99392a38e4188b",
            "6c501e051d734a638307efa223bc1ca6",
            "fe936344103d467cab6e8c6dea6c79ba",
            "ceda38cd2950449fb11dcc24791fdb4a",
            "f78f83a8979f4f12a3c65261712f2a16",
            "4d4d49617b73482f9c22909ab80419a2",
            "fd2d639359264067aead66bfc0912b09",
            "886a1126e7034f67bd1851958fd158d4",
            "cb2621e3de5c4797b7bd0eadfdbd6a8f",
            "622063613fc941c7be4e57a10b11a28f",
            "b23a21256e144f53ab2c9777b8a0d232",
            "fb71fa7eb3c3492088385f4c34ba3291",
            "dfb4481d9b1148d5a9fead57a1eb0076",
            "9f2615b4b3d24de6a962df4c21ee3940",
            "7e405e9347f045b68c1e21ab52a46cbb",
            "ec590bbca56f47fc9acbf93c25b51884",
            "92bc47337c0848f0983a72a7c6147d60",
            "30cbc986962f47ac992c94ebc5fbc087",
            "d3a4827d2aa54963ad40b522c26bfd0b",
            "e7d07b5178a04082babddcbf2771db58",
            "80cff1e871684b67a9ae59c98cb203d3",
            "16bf9d5d92de41a4b3925468870e28e4",
            "642925bc999b4611840541820f05f692",
            "981ea2c6ceff4bd0994f26de8b7ac070",
            "cb7f178a8c9147edb8afcba3b91667a7",
            "e21a18582aba4eaea09377324da39af7",
            "9c0929793af749c3baef841ea6deafc3"
          ]
        },
        "id": "qBY1bSR-AqSS",
        "outputId": "b12d07c9-bf48-4ece-c366-af06bb1bf69b"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "93a57f9e4dec4d85a4cb125bf0576127",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "README.md: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "45be4ecc0f79450abdda20a8385d1e27",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "train.csv:   0%|          | 0.00/11.3M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d86b1a831ed7487f9b744d912ea6f59f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "validation.csv: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5197bc8b931648fcb53e79868bc5f359",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "test.csv: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1afe0bd24ca2465491962aca4c7ba705",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating train split:   0%|          | 0/12460 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4d4d49617b73482f9c22909ab80419a2",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating validation split:   0%|          | 0/500 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "92bc47337c0848f0983a72a7c6147d60",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating test split:   0%|          | 0/1500 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Load the dataset\n",
        "dataset = load_dataset(\"knkarthick/dialogsum\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241,
          "referenced_widgets": [
            "17da987eaf2b466b9fa0bc5a42fb4efa",
            "1b41c4f9d1e84065a665484f0b6372ad",
            "07e9f2d229024ddb8d033540caf5a6fd",
            "e48a9463c71b4ccfbae0cb49f092ca00",
            "717311396ecc43b3a91794d50895e398",
            "e6e810658a3d42e68a8089818e83f9ad",
            "896b22c1fd02408ca1ba53d34ad387e5",
            "f2b6780be2d546b39d9db117b2e728b1",
            "90e9c2872a0c4538aab58ee718749284",
            "f841498682aa43159afaf896214cbb54",
            "3d65336f8d044cedb1c708b9deb06259",
            "1be14b088f134a96974fef1515006baa",
            "82ca6296fdd2495892168403f08e80c7",
            "5ff7b73a54064cff9c3f13753bcf0e13",
            "449e132ed79949e296941bbc8768b481",
            "fdbbc182ab0b4812aa3e3b585a53867d",
            "0d677a743cba4bbea2177869a150ac4e",
            "e46f5a92a0064c9d9b8bde8fab633934",
            "a61e2f83d7de43d3a95cfe7b5aa0f687",
            "b8fe8a71873d4314ab9489fc1243aff2",
            "01ecedb0a59c4e559aae64f6ef677680",
            "680b0d05ba174facb643b6e951b70329",
            "629a6fc6c7d146e49ea96f9fdad123ee",
            "a3417600bbf74f5e8e119453286988f0",
            "f23e51b450004d54af68199cdde3d138",
            "e299685261654509a2f483a295b716f8",
            "0e1f7825a29b4b368da0c86d8ae4aa73",
            "a54502f640c5460a9da7cafbdc479849",
            "f28b66aaadac4831b0e01ebcb28ad518",
            "1624bcd269d34c58bacb92fa94e7693e",
            "8600ad1e00924964981229432ff918ea",
            "a55aa13ddf634cb9bda49c13c27399fd",
            "7753fa93731e4b90a81ac3199723797d",
            "9bf54d4550cb4c6bb13008d5d16ebce5",
            "f9e38b8ebe6a485a898ce0d8d1b2fcc9",
            "7a5fb324e9584fdebda95b39432b84e8",
            "134dd8cfe66c4cca8601742eefb1af22",
            "11fb422a962449418621015b941c4b85",
            "8a219778d4194d03bcca63c3fca1e93f",
            "e0992bc449d64ccd9fc457795357ac59",
            "d9b0b206f43b426ea93e0a17ab3c2744",
            "0c76d88c8e764660ba42ac4dc4bf1304",
            "fa7923c6be9448b98ffd0b9721296270",
            "d9e9ab9f09fd42759956b0ed1edc738b",
            "fd8bd5579c1947038b31411b7440f460",
            "e36bb53a369541279d0d1199cba9c732",
            "8d1bbb23c9aa4f5f972f670e49c99d05",
            "5178a183e0174080b513c55a3a96c70d",
            "d34ab8ff28c84fc3a145f2891bf5f3c6",
            "97ab7f209ec84d4aaa8dbe75d89a2ddc",
            "00420264cd6649f4a96b05443a2d2bc0",
            "e8c84dacf6e445e3ae44e3c69577165a",
            "54c264d04e024177a8a38c50bf186a46",
            "e8aa07a340174d14bcb75557bdeb32bd",
            "cd94834157d344268ea74f2ace9e13a8",
            "cac40da82f17428185f3de2224b14cdc",
            "56a1035132c64f90a50625956dfab3ea",
            "989a531d0cb7435d859305353faaf0eb",
            "55c56670abfc4e04ac1a05f8ad813589",
            "93ba93d7d53443248f27f6a43bccebd7",
            "eaf5f50e85044feeb221fb5438f2f3ed",
            "7944c206723d4ef98d9344497eea50f0",
            "2ad933aa39214b2aa32d77978d150935",
            "17d3c9dd27c640c8b67913b24ebeb377",
            "d308bac88c674e62bd1e3fc2292d5ab0",
            "5ee53d84a1f240e2803fd52015287431",
            "350b9648ff364f1f9e310ad307558362",
            "34a57007f41a46f3a4cea056ebc58ec5",
            "e29f6d0003654094aa4f35a943dd71f6",
            "ba1018abb26046b8b8fd5e4f6747a97a",
            "c91ab6fec07847f0957a475a1479c163",
            "cbebb88b56dd47ddb27226a81d60d141",
            "275a6dae3f824bf9b348c41240d523fa",
            "6e252c6ba9964c988ab5fc2173e4971d",
            "6ea8a8682a3f4f3ba3770ea2f7a376fd",
            "94e110f6ee5b4201b0d21c00b616875b",
            "ed46237b70a04f028f1067f6fbef652f"
          ]
        },
        "id": "5uI8NzmnGFcL",
        "outputId": "31c09faf-ffba-4c13-efd0-8177e3f129d0"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "17da987eaf2b466b9fa0bc5a42fb4efa",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer_config.json: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1be14b088f134a96974fef1515006baa",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "629a6fc6c7d146e49ea96f9fdad123ee",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer.json: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9bf54d4550cb4c6bb13008d5d16ebce5",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "special_tokens_map.json: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "fd8bd5579c1947038b31411b7440f460",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "cac40da82f17428185f3de2224b14cdc",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/990M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "350b9648ff364f1f9e310ad307558362",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/147 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Load the model\n",
        "model_ckpt = 'google/flan-t5-base'\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_ckpt)\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(model_ckpt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 126
        },
        "id": "1I8FQLM23Wrl",
        "outputId": "bf6d6317-0657-40b6-fd36-cf1d13ebe60e"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"#Person1#: Hi, Mr. Smith. I'm Doctor Hawkins. Why are you here today?\\n#Person2#: I found it would be a good idea to get a check-up.\\n#Person1#: Yes, well, you haven't had one for 5 years. You should have one every year.\\n#Person2#: I know. I figure as long as there is nothing wrong, why go see the doctor?\\n#Person1#: Well, the best way to avoid serious illnesses is to find out about them early. So try to come at least once a year for your own good.\\n#Person2#: Ok.\\n#Person1#: Let me see here. Your eyes and ears look fine. Take a deep breath, please. Do you smoke, Mr. Smith?\\n#Person2#: Yes.\\n#Person1#: Smoking is the leading cause of lung cancer and heart disease, you know. You really should quit.\\n#Person2#: I've tried hundreds of times, but I just can't seem to kick the habit.\\n#Person1#: Well, we have classes and some medications that might help. I'll give you more information before you leave.\\n#Person2#: Ok, thanks doctor.\""
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataset['train']['dialogue'][0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 113,
          "referenced_widgets": [
            "0b268899264d417589b6f82d7684e2a9",
            "2876ec8b14f148a29f1ce062068da19d",
            "b89953b7e55146ed829002bf2e819364",
            "098b62123a8845618ac4384c7a1bdf5b",
            "022c38bf231c46e2b6219b802f27a0ba",
            "42c4a270a63848eab66c9857def317f9",
            "52ccf642e1e64cf6b543c94f8a225e5c",
            "7952fbc3ba6847e6ac6f6e6601355421",
            "0d142666edcc492b998a087fae87048c",
            "b9937a15d23c456ca9712802bed0c132",
            "35b8f05567fd4db5ac6963749bdcea42",
            "efc451481f284ca5a474375570bc8d25",
            "0c3ce5d6b2c842e8b5e339459c64dff8",
            "26c57d65daa84efba909473bc88984a7",
            "813643fb36b44591befec5108da272c7",
            "52b249b77ec34d8186dfc2a6747d5aaa",
            "fb516185e2fe413195eb0c732d316ea4",
            "be47b92e35e14e9cb7b62ed26cfac675",
            "bc66974383c34ae5a04f6c4d13df00b2",
            "d88ccf79d45041daaa764e820f7f2843",
            "fb0c1719885a49aa8fae5abce1183b12",
            "3c3e3791600b485d9cbe33d9ced994e4",
            "df82fa3710ce44cbb0c68103da6ac805",
            "0b7ce48736c0417490caf4b4c9cfac3b",
            "f6b71f3e21de46c0941ca85d8a523cf0",
            "c17ed1f51a1147559d7e170c4739de5f",
            "b0152391679f43688f40b0bbfa0bbfc0",
            "1754eae37a6b41f2b288e649f52ccf20",
            "12224255a64844938d171126c6a6b280",
            "b8a153f55a4d4f0fb65e66deb238fdff",
            "9953d8bc4da54c30850c82468e274522",
            "ac043c64f2754244a3ad4da7936f7806",
            "d14f68fe97bc49e6a55c9f24e3870fe9"
          ]
        },
        "id": "DsfkLsivGT2m",
        "outputId": "6659c994-50d1-4465-dc45-6e99a649e294"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0b268899264d417589b6f82d7684e2a9",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/12460 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "efc451481f284ca5a474375570bc8d25",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/500 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "df82fa3710ce44cbb0c68103da6ac805",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/1500 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Tokenization function\n",
        "def tokenize_function(batch):\n",
        "\n",
        "  # Start and end prompt between dialogue\n",
        "  start_prompt = 'Summarize the following conversation.\\n\\n'\n",
        "  end_prompt = '\\n\\nSummary: '\n",
        "  prompt = [start_prompt + dialogue + end_prompt for dialogue in batch[\"dialogue\"]]\n",
        "\n",
        "  # Tokenizing the prompt and the label, taking the input_ids and add them to the batch dict\n",
        "  batch['input_ids'] = tokenizer(prompt, padding=\"max_length\", truncation=True, return_tensors=\"pt\").input_ids\n",
        "  batch['labels'] = tokenizer(batch[\"summary\"], padding=\"max_length\", truncation=True, return_tensors=\"pt\").input_ids\n",
        "\n",
        "  return batch\n",
        "\n",
        "# Apply using map function\n",
        "tokenized_datasets = dataset.map(tokenize_function, batched=True)\n",
        "tokenized_datasets = tokenized_datasets.remove_columns(['id', 'topic', 'dialogue', 'summary'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "J42sSHqVHLVk"
      },
      "outputs": [],
      "source": [
        "# Setup PEFT/LoRA model for Fine Tuning\n",
        "lora_config = LoraConfig(\n",
        "    r=40,                       # Rank of the low-rank adaptation matrices. The higher this value, the more capacity the model has to learn complex patterns.\n",
        "    lora_alpha=40,              # Scaling factor for the LoRA weights. Controls how much the low-rank matrices affect the model\u2019s parameters.\n",
        "    target_modules=[\"q\", \"v\"],  # Modules to apply LoRA to. Here \"q\" and \"v\" are the query and value matrices in the Transformer architecture.\n",
        "    lora_dropout=0.05,          # Dropout for the LoRA layers, helps prevent overfitting by randomly dropping units during training.\n",
        "    bias=\"none\",                # No bias terms for LoRA, which simplifies the adaptation to the low-rank matrices.\n",
        "    task_type=TaskType.SEQ_2_SEQ_LM  # Specifies that this is a sequence-to-sequence task (language modeling for FLAN-T5).\n",
        ")\n",
        "\n",
        "# PEFT model\n",
        "peft_model = get_peft_model(model, lora_config)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17,
          "referenced_widgets": [
            "309f9829300c4a37bd55a6e4c9488223",
            "55576fdc81694eb5ab64e2c41450520b",
            "5258b4a3973a4693800b4fa1e9e4f191",
            "02dfff17bf46414d895014621a5520dd",
            "4fb9fce66ad54022b04994c0924072ff",
            "f73be055fee346439090126e84ec39cf",
            "ee5000107f194d8f9d57e011e6a5963e",
            "d36c10659f164e5cb694410b8b285d32",
            "757665e1a17d4b55bde4746aa716f72f",
            "ecf9bb5f7c8e4f8ea64617481e05f05c",
            "59d5a7ee316443849d210b7d7a004f71",
            "74622ea25c6e47e4b2f97e425502530d",
            "b110d5e7a53f4875b67ddd68371b807a",
            "9698b0c071944e0f92b33260ae616c2b",
            "1118697ba53d4db3aa9f005d76eb787d",
            "4b012f0e98224f4185840a4ad9134889",
            "eca765a43f1448b69406340ee5cbcb76",
            "17037b66ab7443a597555c97ee47e40e",
            "f60211e05730406f9973dc2060833916",
            "900256f18ac4424e9dbc960f75451632"
          ]
        },
        "id": "7w9K1opjKq_3",
        "outputId": "f39c8425-958f-452f-d131-b2f272328cfe"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "309f9829300c4a37bd55a6e4c9488223",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv\u2026"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Login using Key Token from HuggingFace (to be write permission)\n",
        "notebook_login()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AF3G0S9aKfAH",
        "outputId": "afea0285-b713-4a01-d083-49c53472a191"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "PyTorch: setting up devices\n",
            "average_tokens_across_devices is True but world size is 1. Setting it to False automatically.\n"
          ]
        }
      ],
      "source": [
        "# Training PEFT Adapter\n",
        "output_dir = f'{model_ckpt}-peft-dialogue-summary-abdUllahsamir'\n",
        "\n",
        "batch_size = 2\n",
        "logging_steps = len(tokenized_datasets['train']) // batch_size\n",
        "\n",
        "# Training Arguments\n",
        "peft_training_args = TrainingArguments(\n",
        "    output_dir=output_dir,\n",
        "    num_train_epochs=2,\n",
        "    learning_rate=2e-5,\n",
        "    per_device_train_batch_size=batch_size,\n",
        "    per_device_eval_batch_size=batch_size,\n",
        "    eval_strategy='epoch',\n",
        "    logging_steps=logging_steps,\n",
        "    push_to_hub=True,\n",
        "    log_level='info',\n",
        "    disable_tqdm=False,\n",
        "    report_to=[\"none\"]  # Explicitly disable all reporting integrations\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sY7c7GliNUHT"
      },
      "outputs": [],
      "source": [
        "from transformers import TrainingArguments\n",
        "\n",
        "# 1. \u062a\u062d\u062f\u062f \u0645\u0643\u0627\u0646 \u0627\u0644\u062d\u0641\u0638 + \u0625\u0639\u062f\u0627\u062f\u0627\u062a \u0627\u0644\u062a\u062f\u0631\u064a\u0628\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"/content/drive/MyDrive/peft-checkpoints\",  # \u062c\u0648\u0647 Google Drive\n",
        "    save_strategy=\"epoch\",   # \u0623\u0648 \"steps\"\n",
        "    save_steps=500,          # \u0644\u0648 \u0627\u062e\u062a\u0631\u062a \"steps\"\n",
        "    num_train_epochs=3,\n",
        "    per_device_train_batch_size=2,\n",
        "    logging_dir=\"./logs\",\n",
        "    logging_steps=100,\n",
        "    evaluation_strategy=\"epoch\",  # \u0644\u0648 \u0639\u0627\u064a\u0632 \u062a\u0639\u0645\u0644 eval \u0623\u062b\u0646\u0627\u0621 \u0627\u0644\u062a\u062f\u0631\u064a\u0628\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "HKYHWtFGIxkt",
        "outputId": "56349ad0-2534-4d53-bfa2-4e3742f103c8"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-2576098794.py:2: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  peft_trainer = Trainer(\n",
            "***** Running training *****\n",
            "  Num examples = 12,460\n",
            "  Num Epochs = 2\n",
            "  Instantaneous batch size per device = 2\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 2\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 12,460\n",
            "  Number of trainable parameters = 4,423,680\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='12460' max='12460' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [12460/12460 1:50:23, Epoch 2/2]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>2.110300</td>\n",
              "      <td>0.115174</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.154400</td>\n",
              "      <td>0.106850</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Saving model checkpoint to google/flan-t5-base-peft-dialogue-summary-abdUllahsamir/checkpoint-500\n",
            "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--google--flan-t5-base/snapshots/7bcac572ce56db69c1ea7c8af255c5d7c9672fc2/config.json\n",
            "Model config T5Config {\n",
            "  \"architectures\": [\n",
            "    \"T5ForConditionalGeneration\"\n",
            "  ],\n",
            "  \"classifier_dropout\": 0.0,\n",
            "  \"d_ff\": 2048,\n",
            "  \"d_kv\": 64,\n",
            "  \"d_model\": 768,\n",
            "  \"decoder_start_token_id\": 0,\n",
            "  \"dense_act_fn\": \"gelu_new\",\n",
            "  \"dropout_rate\": 0.1,\n",
            "  \"eos_token_id\": 1,\n",
            "  \"feed_forward_proj\": \"gated-gelu\",\n",
            "  \"initializer_factor\": 1.0,\n",
            "  \"is_encoder_decoder\": true,\n",
            "  \"is_gated_act\": true,\n",
            "  \"layer_norm_epsilon\": 1e-06,\n",
            "  \"model_type\": \"t5\",\n",
            "  \"n_positions\": 512,\n",
            "  \"num_decoder_layers\": 12,\n",
            "  \"num_heads\": 12,\n",
            "  \"num_layers\": 12,\n",
            "  \"output_past\": true,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"relative_attention_max_distance\": 128,\n",
            "  \"relative_attention_num_buckets\": 32,\n",
            "  \"task_specific_params\": {\n",
            "    \"summarization\": {\n",
            "      \"early_stopping\": true,\n",
            "      \"length_penalty\": 2.0,\n",
            "      \"max_length\": 200,\n",
            "      \"min_length\": 30,\n",
            "      \"no_repeat_ngram_size\": 3,\n",
            "      \"num_beams\": 4,\n",
            "      \"prefix\": \"summarize: \"\n",
            "    },\n",
            "    \"translation_en_to_de\": {\n",
            "      \"early_stopping\": true,\n",
            "      \"max_length\": 300,\n",
            "      \"num_beams\": 4,\n",
            "      \"prefix\": \"translate English to German: \"\n",
            "    },\n",
            "    \"translation_en_to_fr\": {\n",
            "      \"early_stopping\": true,\n",
            "      \"max_length\": 300,\n",
            "      \"num_beams\": 4,\n",
            "      \"prefix\": \"translate English to French: \"\n",
            "    },\n",
            "    \"translation_en_to_ro\": {\n",
            "      \"early_stopping\": true,\n",
            "      \"max_length\": 300,\n",
            "      \"num_beams\": 4,\n",
            "      \"prefix\": \"translate English to Romanian: \"\n",
            "    }\n",
            "  },\n",
            "  \"tie_word_embeddings\": false,\n",
            "  \"transformers_version\": \"4.55.2\",\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 32128\n",
            "}\n",
            "\n",
            "tokenizer config file saved in google/flan-t5-base-peft-dialogue-summary-abdUllahsamir/checkpoint-500/tokenizer_config.json\n",
            "Special tokens file saved in google/flan-t5-base-peft-dialogue-summary-abdUllahsamir/checkpoint-500/special_tokens_map.json\n",
            "Copy vocab file to google/flan-t5-base-peft-dialogue-summary-abdUllahsamir/checkpoint-500/spiece.model\n",
            "tokenizer config file saved in google/flan-t5-base-peft-dialogue-summary-abdUllahsamir/tokenizer_config.json\n",
            "Special tokens file saved in google/flan-t5-base-peft-dialogue-summary-abdUllahsamir/special_tokens_map.json\n",
            "Copy vocab file to google/flan-t5-base-peft-dialogue-summary-abdUllahsamir/spiece.model\n",
            "Saving model checkpoint to google/flan-t5-base-peft-dialogue-summary-abdUllahsamir/checkpoint-1000\n",
            "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--google--flan-t5-base/snapshots/7bcac572ce56db69c1ea7c8af255c5d7c9672fc2/config.json\n",
            "Model config T5Config {\n",
            "  \"architectures\": [\n",
            "    \"T5ForConditionalGeneration\"\n",
            "  ],\n",
            "  \"classifier_dropout\": 0.0,\n",
            "  \"d_ff\": 2048,\n",
            "  \"d_kv\": 64,\n",
            "  \"d_model\": 768,\n",
            "  \"decoder_start_token_id\": 0,\n",
            "  \"dense_act_fn\": \"gelu_new\",\n",
            "  \"dropout_rate\": 0.1,\n",
            "  \"eos_token_id\": 1,\n",
            "  \"feed_forward_proj\": \"gated-gelu\",\n",
            "  \"initializer_factor\": 1.0,\n",
            "  \"is_encoder_decoder\": true,\n",
            "  \"is_gated_act\": true,\n",
            "  \"layer_norm_epsilon\": 1e-06,\n",
            "  \"model_type\": \"t5\",\n",
            "  \"n_positions\": 512,\n",
            "  \"num_decoder_layers\": 12,\n",
            "  \"num_heads\": 12,\n",
            "  \"num_layers\": 12,\n",
            "  \"output_past\": true,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"relative_attention_max_distance\": 128,\n",
            "  \"relative_attention_num_buckets\": 32,\n",
            "  \"task_specific_params\": {\n",
            "    \"summarization\": {\n",
            "      \"early_stopping\": true,\n",
            "      \"length_penalty\": 2.0,\n",
            "      \"max_length\": 200,\n",
            "      \"min_length\": 30,\n",
            "      \"no_repeat_ngram_size\": 3,\n",
            "      \"num_beams\": 4,\n",
            "      \"prefix\": \"summarize: \"\n",
            "    },\n",
            "    \"translation_en_to_de\": {\n",
            "      \"early_stopping\": true,\n",
            "      \"max_length\": 300,\n",
            "      \"num_beams\": 4,\n",
            "      \"prefix\": \"translate English to German: \"\n",
            "    },\n",
            "    \"translation_en_to_fr\": {\n",
            "      \"early_stopping\": true,\n",
            "      \"max_length\": 300,\n",
            "      \"num_beams\": 4,\n",
            "      \"prefix\": \"translate English to French: \"\n",
            "    },\n",
            "    \"translation_en_to_ro\": {\n",
            "      \"early_stopping\": true,\n",
            "      \"max_length\": 300,\n",
            "      \"num_beams\": 4,\n",
            "      \"prefix\": \"translate English to Romanian: \"\n",
            "    }\n",
            "  },\n",
            "  \"tie_word_embeddings\": false,\n",
            "  \"transformers_version\": \"4.55.2\",\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 32128\n",
            "}\n",
            "\n",
            "tokenizer config file saved in google/flan-t5-base-peft-dialogue-summary-abdUllahsamir/checkpoint-1000/tokenizer_config.json\n",
            "Special tokens file saved in google/flan-t5-base-peft-dialogue-summary-abdUllahsamir/checkpoint-1000/special_tokens_map.json\n",
            "Copy vocab file to google/flan-t5-base-peft-dialogue-summary-abdUllahsamir/checkpoint-1000/spiece.model\n",
            "tokenizer config file saved in google/flan-t5-base-peft-dialogue-summary-abdUllahsamir/tokenizer_config.json\n",
            "Special tokens file saved in google/flan-t5-base-peft-dialogue-summary-abdUllahsamir/special_tokens_map.json\n",
            "Copy vocab file to google/flan-t5-base-peft-dialogue-summary-abdUllahsamir/spiece.model\n",
            "Saving model checkpoint to google/flan-t5-base-peft-dialogue-summary-abdUllahsamir/checkpoint-1500\n",
            "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--google--flan-t5-base/snapshots/7bcac572ce56db69c1ea7c8af255c5d7c9672fc2/config.json\n",
            "Model config T5Config {\n",
            "  \"architectures\": [\n",
            "    \"T5ForConditionalGeneration\"\n",
            "  ],\n",
            "  \"classifier_dropout\": 0.0,\n",
            "  \"d_ff\": 2048,\n",
            "  \"d_kv\": 64,\n",
            "  \"d_model\": 768,\n",
            "  \"decoder_start_token_id\": 0,\n",
            "  \"dense_act_fn\": \"gelu_new\",\n",
            "  \"dropout_rate\": 0.1,\n",
            "  \"eos_token_id\": 1,\n",
            "  \"feed_forward_proj\": \"gated-gelu\",\n",
            "  \"initializer_factor\": 1.0,\n",
            "  \"is_encoder_decoder\": true,\n",
            "  \"is_gated_act\": true,\n",
            "  \"layer_norm_epsilon\": 1e-06,\n",
            "  \"model_type\": \"t5\",\n",
            "  \"n_positions\": 512,\n",
            "  \"num_decoder_layers\": 12,\n",
            "  \"num_heads\": 12,\n",
            "  \"num_layers\": 12,\n",
            "  \"output_past\": true,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"relative_attention_max_distance\": 128,\n",
            "  \"relative_attention_num_buckets\": 32,\n",
            "  \"task_specific_params\": {\n",
            "    \"summarization\": {\n",
            "      \"early_stopping\": true,\n",
            "      \"length_penalty\": 2.0,\n",
            "      \"max_length\": 200,\n",
            "      \"min_length\": 30,\n",
            "      \"no_repeat_ngram_size\": 3,\n",
            "      \"num_beams\": 4,\n",
            "      \"prefix\": \"summarize: \"\n",
            "    },\n",
            "    \"translation_en_to_de\": {\n",
            "      \"early_stopping\": true,\n",
            "      \"max_length\": 300,\n",
            "      \"num_beams\": 4,\n",
            "      \"prefix\": \"translate English to German: \"\n",
            "    },\n",
            "    \"translation_en_to_fr\": {\n",
            "      \"early_stopping\": true,\n",
            "      \"max_length\": 300,\n",
            "      \"num_beams\": 4,\n",
            "      \"prefix\": \"translate English to French: \"\n",
            "    },\n",
            "    \"translation_en_to_ro\": {\n",
            "      \"early_stopping\": true,\n",
            "      \"max_length\": 300,\n",
            "      \"num_beams\": 4,\n",
            "      \"prefix\": \"translate English to Romanian: \"\n",
            "    }\n",
            "  },\n",
            "  \"tie_word_embeddings\": false,\n",
            "  \"transformers_version\": \"4.55.2\",\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 32128\n",
            "}\n",
            "\n",
            "tokenizer config file saved in google/flan-t5-base-peft-dialogue-summary-abdUllahsamir/checkpoint-1500/tokenizer_config.json\n",
            "Special tokens file saved in google/flan-t5-base-peft-dialogue-summary-abdUllahsamir/checkpoint-1500/special_tokens_map.json\n",
            "Copy vocab file to google/flan-t5-base-peft-dialogue-summary-abdUllahsamir/checkpoint-1500/spiece.model\n",
            "tokenizer config file saved in google/flan-t5-base-peft-dialogue-summary-abdUllahsamir/tokenizer_config.json\n",
            "Special tokens file saved in google/flan-t5-base-peft-dialogue-summary-abdUllahsamir/special_tokens_map.json\n",
            "Copy vocab file to google/flan-t5-base-peft-dialogue-summary-abdUllahsamir/spiece.model\n",
            "Saving model checkpoint to google/flan-t5-base-peft-dialogue-summary-abdUllahsamir/checkpoint-2000\n",
            "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--google--flan-t5-base/snapshots/7bcac572ce56db69c1ea7c8af255c5d7c9672fc2/config.json\n",
            "Model config T5Config {\n",
            "  \"architectures\": [\n",
            "    \"T5ForConditionalGeneration\"\n",
            "  ],\n",
            "  \"classifier_dropout\": 0.0,\n",
            "  \"d_ff\": 2048,\n",
            "  \"d_kv\": 64,\n",
            "  \"d_model\": 768,\n",
            "  \"decoder_start_token_id\": 0,\n",
            "  \"dense_act_fn\": \"gelu_new\",\n",
            "  \"dropout_rate\": 0.1,\n",
            "  \"eos_token_id\": 1,\n",
            "  \"feed_forward_proj\": \"gated-gelu\",\n",
            "  \"initializer_factor\": 1.0,\n",
            "  \"is_encoder_decoder\": true,\n",
            "  \"is_gated_act\": true,\n",
            "  \"layer_norm_epsilon\": 1e-06,\n",
            "  \"model_type\": \"t5\",\n",
            "  \"n_positions\": 512,\n",
            "  \"num_decoder_layers\": 12,\n",
            "  \"num_heads\": 12,\n",
            "  \"num_layers\": 12,\n",
            "  \"output_past\": true,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"relative_attention_max_distance\": 128,\n",
            "  \"relative_attention_num_buckets\": 32,\n",
            "  \"task_specific_params\": {\n",
            "    \"summarization\": {\n",
            "      \"early_stopping\": true,\n",
            "      \"length_penalty\": 2.0,\n",
            "      \"max_length\": 200,\n",
            "      \"min_length\": 30,\n",
            "      \"no_repeat_ngram_size\": 3,\n",
            "      \"num_beams\": 4,\n",
            "      \"prefix\": \"summarize: \"\n",
            "    },\n",
            "    \"translation_en_to_de\": {\n",
            "      \"early_stopping\": true,\n",
            "      \"max_length\": 300,\n",
            "      \"num_beams\": 4,\n",
            "      \"prefix\": \"translate English to German: \"\n",
            "    },\n",
            "    \"translation_en_to_fr\": {\n",
            "      \"early_stopping\": true,\n",
            "      \"max_length\": 300,\n",
            "      \"num_beams\": 4,\n",
            "      \"prefix\": \"translate English to French: \"\n",
            "    },\n",
            "    \"translation_en_to_ro\": {\n",
            "      \"early_stopping\": true,\n",
            "      \"max_length\": 300,\n",
            "      \"num_beams\": 4,\n",
            "      \"prefix\": \"translate English to Romanian: \"\n",
            "    }\n",
            "  },\n",
            "  \"tie_word_embeddings\": false,\n",
            "  \"transformers_version\": \"4.55.2\",\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 32128\n",
            "}\n",
            "\n",
            "tokenizer config file saved in google/flan-t5-base-peft-dialogue-summary-abdUllahsamir/checkpoint-2000/tokenizer_config.json\n",
            "Special tokens file saved in google/flan-t5-base-peft-dialogue-summary-abdUllahsamir/checkpoint-2000/special_tokens_map.json\n",
            "Copy vocab file to google/flan-t5-base-peft-dialogue-summary-abdUllahsamir/checkpoint-2000/spiece.model\n",
            "tokenizer config file saved in google/flan-t5-base-peft-dialogue-summary-abdUllahsamir/tokenizer_config.json\n",
            "Special tokens file saved in google/flan-t5-base-peft-dialogue-summary-abdUllahsamir/special_tokens_map.json\n",
            "Copy vocab file to google/flan-t5-base-peft-dialogue-summary-abdUllahsamir/spiece.model\n",
            "Saving model checkpoint to google/flan-t5-base-peft-dialogue-summary-abdUllahsamir/checkpoint-2500\n",
            "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--google--flan-t5-base/snapshots/7bcac572ce56db69c1ea7c8af255c5d7c9672fc2/config.json\n",
            "Model config T5Config {\n",
            "  \"architectures\": [\n",
            "    \"T5ForConditionalGeneration\"\n",
            "  ],\n",
            "  \"classifier_dropout\": 0.0,\n",
            "  \"d_ff\": 2048,\n",
            "  \"d_kv\": 64,\n",
            "  \"d_model\": 768,\n",
            "  \"decoder_start_token_id\": 0,\n",
            "  \"dense_act_fn\": \"gelu_new\",\n",
            "  \"dropout_rate\": 0.1,\n",
            "  \"eos_token_id\": 1,\n",
            "  \"feed_forward_proj\": \"gated-gelu\",\n",
            "  \"initializer_factor\": 1.0,\n",
            "  \"is_encoder_decoder\": true,\n",
            "  \"is_gated_act\": true,\n",
            "  \"layer_norm_epsilon\": 1e-06,\n",
            "  \"model_type\": \"t5\",\n",
            "  \"n_positions\": 512,\n",
            "  \"num_decoder_layers\": 12,\n",
            "  \"num_heads\": 12,\n",
            "  \"num_layers\": 12,\n",
            "  \"output_past\": true,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"relative_attention_max_distance\": 128,\n",
            "  \"relative_attention_num_buckets\": 32,\n",
            "  \"task_specific_params\": {\n",
            "    \"summarization\": {\n",
            "      \"early_stopping\": true,\n",
            "      \"length_penalty\": 2.0,\n",
            "      \"max_length\": 200,\n",
            "      \"min_length\": 30,\n",
            "      \"no_repeat_ngram_size\": 3,\n",
            "      \"num_beams\": 4,\n",
            "      \"prefix\": \"summarize: \"\n",
            "    },\n",
            "    \"translation_en_to_de\": {\n",
            "      \"early_stopping\": true,\n",
            "      \"max_length\": 300,\n",
            "      \"num_beams\": 4,\n",
            "      \"prefix\": \"translate English to German: \"\n",
            "    },\n",
            "    \"translation_en_to_fr\": {\n",
            "      \"early_stopping\": true,\n",
            "      \"max_length\": 300,\n",
            "      \"num_beams\": 4,\n",
            "      \"prefix\": \"translate English to French: \"\n",
            "    },\n",
            "    \"translation_en_to_ro\": {\n",
            "      \"early_stopping\": true,\n",
            "      \"max_length\": 300,\n",
            "      \"num_beams\": 4,\n",
            "      \"prefix\": \"translate English to Romanian: \"\n",
            "    }\n",
            "  },\n",
            "  \"tie_word_embeddings\": false,\n",
            "  \"transformers_version\": \"4.55.2\",\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 32128\n",
            "}\n",
            "\n",
            "tokenizer config file saved in google/flan-t5-base-peft-dialogue-summary-abdUllahsamir/checkpoint-2500/tokenizer_config.json\n",
            "Special tokens file saved in google/flan-t5-base-peft-dialogue-summary-abdUllahsamir/checkpoint-2500/special_tokens_map.json\n",
            "Copy vocab file to google/flan-t5-base-peft-dialogue-summary-abdUllahsamir/checkpoint-2500/spiece.model\n",
            "tokenizer config file saved in google/flan-t5-base-peft-dialogue-summary-abdUllahsamir/tokenizer_config.json\n",
            "Special tokens file saved in google/flan-t5-base-peft-dialogue-summary-abdUllahsamir/special_tokens_map.json\n",
            "Copy vocab file to google/flan-t5-base-peft-dialogue-summary-abdUllahsamir/spiece.model\n",
            "Saving model checkpoint to google/flan-t5-base-peft-dialogue-summary-abdUllahsamir/checkpoint-3000\n",
            "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--google--flan-t5-base/snapshots/7bcac572ce56db69c1ea7c8af255c5d7c9672fc2/config.json\n",
            "Model config T5Config {\n",
            "  \"architectures\": [\n",
            "    \"T5ForConditionalGeneration\"\n",
            "  ],\n",
            "  \"classifier_dropout\": 0.0,\n",
            "  \"d_ff\": 2048,\n",
            "  \"d_kv\": 64,\n",
            "  \"d_model\": 768,\n",
            "  \"decoder_start_token_id\": 0,\n",
            "  \"dense_act_fn\": \"gelu_new\",\n",
            "  \"dropout_rate\": 0.1,\n",
            "  \"eos_token_id\": 1,\n",
            "  \"feed_forward_proj\": \"gated-gelu\",\n",
            "  \"initializer_factor\": 1.0,\n",
            "  \"is_encoder_decoder\": true,\n",
            "  \"is_gated_act\": true,\n",
            "  \"layer_norm_epsilon\": 1e-06,\n",
            "  \"model_type\": \"t5\",\n",
            "  \"n_positions\": 512,\n",
            "  \"num_decoder_layers\": 12,\n",
            "  \"num_heads\": 12,\n",
            "  \"num_layers\": 12,\n",
            "  \"output_past\": true,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"relative_attention_max_distance\": 128,\n",
            "  \"relative_attention_num_buckets\": 32,\n",
            "  \"task_specific_params\": {\n",
            "    \"summarization\": {\n",
            "      \"early_stopping\": true,\n",
            "      \"length_penalty\": 2.0,\n",
            "      \"max_length\": 200,\n",
            "      \"min_length\": 30,\n",
            "      \"no_repeat_ngram_size\": 3,\n",
            "      \"num_beams\": 4,\n",
            "      \"prefix\": \"summarize: \"\n",
            "    },\n",
            "    \"translation_en_to_de\": {\n",
            "      \"early_stopping\": true,\n",
            "      \"max_length\": 300,\n",
            "      \"num_beams\": 4,\n",
            "      \"prefix\": \"translate English to German: \"\n",
            "    },\n",
            "    \"translation_en_to_fr\": {\n",
            "      \"early_stopping\": true,\n",
            "      \"max_length\": 300,\n",
            "      \"num_beams\": 4,\n",
            "      \"prefix\": \"translate English to French: \"\n",
            "    },\n",
            "    \"translation_en_to_ro\": {\n",
            "      \"early_stopping\": true,\n",
            "      \"max_length\": 300,\n",
            "      \"num_beams\": 4,\n",
            "      \"prefix\": \"translate English to Romanian: \"\n",
            "    }\n",
            "  },\n",
            "  \"tie_word_embeddings\": false,\n",
            "  \"transformers_version\": \"4.55.2\",\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 32128\n",
            "}\n",
            "\n",
            "tokenizer config file saved in google/flan-t5-base-peft-dialogue-summary-abdUllahsamir/checkpoint-3000/tokenizer_config.json\n",
            "Special tokens file saved in google/flan-t5-base-peft-dialogue-summary-abdUllahsamir/checkpoint-3000/special_tokens_map.json\n",
            "Copy vocab file to google/flan-t5-base-peft-dialogue-summary-abdUllahsamir/checkpoint-3000/spiece.model\n",
            "tokenizer config file saved in google/flan-t5-base-peft-dialogue-summary-abdUllahsamir/tokenizer_config.json\n",
            "Special tokens file saved in google/flan-t5-base-peft-dialogue-summary-abdUllahsamir/special_tokens_map.json\n",
            "Copy vocab file to google/flan-t5-base-peft-dialogue-summary-abdUllahsamir/spiece.model\n",
            "Saving model checkpoint to google/flan-t5-base-peft-dialogue-summary-abdUllahsamir/checkpoint-3500\n",
            "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--google--flan-t5-base/snapshots/7bcac572ce56db69c1ea7c8af255c5d7c9672fc2/config.json\n",
            "Model config T5Config {\n",
            "  \"architectures\": [\n",
            "    \"T5ForConditionalGeneration\"\n",
            "  ],\n",
            "  \"classifier_dropout\": 0.0,\n",
            "  \"d_ff\": 2048,\n",
            "  \"d_kv\": 64,\n",
            "  \"d_model\": 768,\n",
            "  \"decoder_start_token_id\": 0,\n",
            "  \"dense_act_fn\": \"gelu_new\",\n",
            "  \"dropout_rate\": 0.1,\n",
            "  \"eos_token_id\": 1,\n",
            "  \"feed_forward_proj\": \"gated-gelu\",\n",
            "  \"initializer_factor\": 1.0,\n",
            "  \"is_encoder_decoder\": true,\n",
            "  \"is_gated_act\": true,\n",
            "  \"layer_norm_epsilon\": 1e-06,\n",
            "  \"model_type\": \"t5\",\n",
            "  \"n_positions\": 512,\n",
            "  \"num_decoder_layers\": 12,\n",
            "  \"num_heads\": 12,\n",
            "  \"num_layers\": 12,\n",
            "  \"output_past\": true,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"relative_attention_max_distance\": 128,\n",
            "  \"relative_attention_num_buckets\": 32,\n",
            "  \"task_specific_params\": {\n",
            "    \"summarization\": {\n",
            "      \"early_stopping\": true,\n",
            "      \"length_penalty\": 2.0,\n",
            "      \"max_length\": 200,\n",
            "      \"min_length\": 30,\n",
            "      \"no_repeat_ngram_size\": 3,\n",
            "      \"num_beams\": 4,\n",
            "      \"prefix\": \"summarize: \"\n",
            "    },\n",
            "    \"translation_en_to_de\": {\n",
            "      \"early_stopping\": true,\n",
            "      \"max_length\": 300,\n",
            "      \"num_beams\": 4,\n",
            "      \"prefix\": \"translate English to German: \"\n",
            "    },\n",
            "    \"translation_en_to_fr\": {\n",
            "      \"early_stopping\": true,\n",
            "      \"max_length\": 300,\n",
            "      \"num_beams\": 4,\n",
            "      \"prefix\": \"translate English to French: \"\n",
            "    },\n",
            "    \"translation_en_to_ro\": {\n",
            "      \"early_stopping\": true,\n",
            "      \"max_length\": 300,\n",
            "      \"num_beams\": 4,\n",
            "      \"prefix\": \"translate English to Romanian: \"\n",
            "    }\n",
            "  },\n",
            "  \"tie_word_embeddings\": false,\n",
            "  \"transformers_version\": \"4.55.2\",\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 32128\n",
            "}\n",
            "\n",
            "tokenizer config file saved in google/flan-t5-base-peft-dialogue-summary-abdUllahsamir/checkpoint-3500/tokenizer_config.json\n",
            "Special tokens file saved in google/flan-t5-base-peft-dialogue-summary-abdUllahsamir/checkpoint-3500/special_tokens_map.json\n",
            "Copy vocab file to google/flan-t5-base-peft-dialogue-summary-abdUllahsamir/checkpoint-3500/spiece.model\n",
            "tokenizer config file saved in google/flan-t5-base-peft-dialogue-summary-abdUllahsamir/tokenizer_config.json\n",
            "Special tokens file saved in google/flan-t5-base-peft-dialogue-summary-abdUllahsamir/special_tokens_map.json\n",
            "Copy vocab file to google/flan-t5-base-peft-dialogue-summary-abdUllahsamir/spiece.model\n",
            "Saving model checkpoint to google/flan-t5-base-peft-dialogue-summary-abdUllahsamir/checkpoint-4000\n",
            "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--google--flan-t5-base/snapshots/7bcac572ce56db69c1ea7c8af255c5d7c9672fc2/config.json\n",
            "Model config T5Config {\n",
            "  \"architectures\": [\n",
            "    \"T5ForConditionalGeneration\"\n",
            "  ],\n",
            "  \"classifier_dropout\": 0.0,\n",
            "  \"d_ff\": 2048,\n",
            "  \"d_kv\": 64,\n",
            "  \"d_model\": 768,\n",
            "  \"decoder_start_token_id\": 0,\n",
            "  \"dense_act_fn\": \"gelu_new\",\n",
            "  \"dropout_rate\": 0.1,\n",
            "  \"eos_token_id\": 1,\n",
            "  \"feed_forward_proj\": \"gated-gelu\",\n",
            "  \"initializer_factor\": 1.0,\n",
            "  \"is_encoder_decoder\": true,\n",
            "  \"is_gated_act\": true,\n",
            "  \"layer_norm_epsilon\": 1e-06,\n",
            "  \"model_type\": \"t5\",\n",
            "  \"n_positions\": 512,\n",
            "  \"num_decoder_layers\": 12,\n",
            "  \"num_heads\": 12,\n",
            "  \"num_layers\": 12,\n",
            "  \"output_past\": true,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"relative_attention_max_distance\": 128,\n",
            "  \"relative_attention_num_buckets\": 32,\n",
            "  \"task_specific_params\": {\n",
            "    \"summarization\": {\n",
            "      \"early_stopping\": true,\n",
            "      \"length_penalty\": 2.0,\n",
            "      \"max_length\": 200,\n",
            "      \"min_length\": 30,\n",
            "      \"no_repeat_ngram_size\": 3,\n",
            "      \"num_beams\": 4,\n",
            "      \"prefix\": \"summarize: \"\n",
            "    },\n",
            "    \"translation_en_to_de\": {\n",
            "      \"early_stopping\": true,\n",
            "      \"max_length\": 300,\n",
            "      \"num_beams\": 4,\n",
            "      \"prefix\": \"translate English to German: \"\n",
            "    },\n",
            "    \"translation_en_to_fr\": {\n",
            "      \"early_stopping\": true,\n",
            "      \"max_length\": 300,\n",
            "      \"num_beams\": 4,\n",
            "      \"prefix\": \"translate English to French: \"\n",
            "    },\n",
            "    \"translation_en_to_ro\": {\n",
            "      \"early_stopping\": true,\n",
            "      \"max_length\": 300,\n",
            "      \"num_beams\": 4,\n",
            "      \"prefix\": \"translate English to Romanian: \"\n",
            "    }\n",
            "  },\n",
            "  \"tie_word_embeddings\": false,\n",
            "  \"transformers_version\": \"4.55.2\",\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 32128\n",
            "}\n",
            "\n",
            "tokenizer config file saved in google/flan-t5-base-peft-dialogue-summary-abdUllahsamir/checkpoint-4000/tokenizer_config.json\n",
            "Special tokens file saved in google/flan-t5-base-peft-dialogue-summary-abdUllahsamir/checkpoint-4000/special_tokens_map.json\n",
            "Copy vocab file to google/flan-t5-base-peft-dialogue-summary-abdUllahsamir/checkpoint-4000/spiece.model\n",
            "tokenizer config file saved in google/flan-t5-base-peft-dialogue-summary-abdUllahsamir/tokenizer_config.json\n",
            "Special tokens file saved in google/flan-t5-base-peft-dialogue-summary-abdUllahsamir/special_tokens_map.json\n",
            "Copy vocab file to google/flan-t5-base-peft-dialogue-summary-abdUllahsamir/spiece.model\n",
            "Saving model checkpoint to google/flan-t5-base-peft-dialogue-summary-abdUllahsamir/checkpoint-4500\n",
            "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--google--flan-t5-base/snapshots/7bcac572ce56db69c1ea7c8af255c5d7c9672fc2/config.json\n",
            "Model config T5Config {\n",
            "  \"architectures\": [\n",
            "    \"T5ForConditionalGeneration\"\n",
            "  ],\n",
            "  \"classifier_dropout\": 0.0,\n",
            "  \"d_ff\": 2048,\n",
            "  \"d_kv\": 64,\n",
            "  \"d_model\": 768,\n",
            "  \"decoder_start_token_id\": 0,\n",
            "  \"dense_act_fn\": \"gelu_new\",\n",
            "  \"dropout_rate\": 0.1,\n",
            "  \"eos_token_id\": 1,\n",
            "  \"feed_forward_proj\": \"gated-gelu\",\n",
            "  \"initializer_factor\": 1.0,\n",
            "  \"is_encoder_decoder\": true,\n",
            "  \"is_gated_act\": true,\n",
            "  \"layer_norm_epsilon\": 1e-06,\n",
            "  \"model_type\": \"t5\",\n",
            "  \"n_positions\": 512,\n",
            "  \"num_decoder_layers\": 12,\n",
            "  \"num_heads\": 12,\n",
            "  \"num_layers\": 12,\n",
            "  \"output_past\": true,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"relative_attention_max_distance\": 128,\n",
            "  \"relative_attention_num_buckets\": 32,\n",
            "  \"task_specific_params\": {\n",
            "    \"summarization\": {\n",
            "      \"early_stopping\": true,\n",
            "      \"length_penalty\": 2.0,\n",
            "      \"max_length\": 200,\n",
            "      \"min_length\": 30,\n",
            "      \"no_repeat_ngram_size\": 3,\n",
            "      \"num_beams\": 4,\n",
            "      \"prefix\": \"summarize: \"\n",
            "    },\n",
            "    \"translation_en_to_de\": {\n",
            "      \"early_stopping\": true,\n",
            "      \"max_length\": 300,\n",
            "      \"num_beams\": 4,\n",
            "      \"prefix\": \"translate English to German: \"\n",
            "    },\n",
            "    \"translation_en_to_fr\": {\n",
            "      \"early_stopping\": true,\n",
            "      \"max_length\": 300,\n",
            "      \"num_beams\": 4,\n",
            "      \"prefix\": \"translate English to French: \"\n",
            "    },\n",
            "    \"translation_en_to_ro\": {\n",
            "      \"early_stopping\": true,\n",
            "      \"max_length\": 300,\n",
            "      \"num_beams\": 4,\n",
            "      \"prefix\": \"translate English to Romanian: \"\n",
            "    }\n",
            "  },\n",
            "  \"tie_word_embeddings\": false,\n",
            "  \"transformers_version\": \"4.55.2\",\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 32128\n",
            "}\n",
            "\n",
            "tokenizer config file saved in google/flan-t5-base-peft-dialogue-summary-abdUllahsamir/checkpoint-4500/tokenizer_config.json\n",
            "Special tokens file saved in google/flan-t5-base-peft-dialogue-summary-abdUllahsamir/checkpoint-4500/special_tokens_map.json\n",
            "Copy vocab file to google/flan-t5-base-peft-dialogue-summary-abdUllahsamir/checkpoint-4500/spiece.model\n",
            "tokenizer config file saved in google/flan-t5-base-peft-dialogue-summary-abdUllahsamir/tokenizer_config.json\n",
            "Special tokens file saved in google/flan-t5-base-peft-dialogue-summary-abdUllahsamir/special_tokens_map.json\n",
            "Copy vocab file to google/flan-t5-base-peft-dialogue-summary-abdUllahsamir/spiece.model\n",
            "Saving model checkpoint to google/flan-t5-base-peft-dialogue-summary-abdUllahsamir/checkpoint-5000\n",
            "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--google--flan-t5-base/snapshots/7bcac572ce56db69c1ea7c8af255c5d7c9672fc2/config.json\n",
            "Model config T5Config {\n",
            "  \"architectures\": [\n",
            "    \"T5ForConditionalGeneration\"\n",
            "  ],\n",
            "  \"classifier_dropout\": 0.0,\n",
            "  \"d_ff\": 2048,\n",
            "  \"d_kv\": 64,\n",
            "  \"d_model\": 768,\n",
            "  \"decoder_start_token_id\": 0,\n",
            "  \"dense_act_fn\": \"gelu_new\",\n",
            "  \"dropout_rate\": 0.1,\n",
            "  \"eos_token_id\": 1,\n",
            "  \"feed_forward_proj\": \"gated-gelu\",\n",
            "  \"initializer_factor\": 1.0,\n",
            "  \"is_encoder_decoder\": true,\n",
            "  \"is_gated_act\": true,\n",
            "  \"layer_norm_epsilon\": 1e-06,\n",
            "  \"model_type\": \"t5\",\n",
            "  \"n_positions\": 512,\n",
            "  \"num_decoder_layers\": 12,\n",
            "  \"num_heads\": 12,\n",
            "  \"num_layers\": 12,\n",
            "  \"output_past\": true,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"relative_attention_max_distance\": 128,\n",
            "  \"relative_attention_num_buckets\": 32,\n",
            "  \"task_specific_params\": {\n",
            "    \"summarization\": {\n",
            "      \"early_stopping\": true,\n",
            "      \"length_penalty\": 2.0,\n",
            "      \"max_length\": 200,\n",
            "      \"min_length\": 30,\n",
            "      \"no_repeat_ngram_size\": 3,\n",
            "      \"num_beams\": 4,\n",
            "      \"prefix\": \"summarize: \"\n",
            "    },\n",
            "    \"translation_en_to_de\": {\n",
            "      \"early_stopping\": true,\n",
            "      \"max_length\": 300,\n",
            "      \"num_beams\": 4,\n",
            "      \"prefix\": \"translate English to German: \"\n",
            "    },\n",
            "    \"translation_en_to_fr\": {\n",
            "      \"early_stopping\": true,\n",
            "      \"max_length\": 300,\n",
            "      \"num_beams\": 4,\n",
            "      \"prefix\": \"translate English to French: \"\n",
            "    },\n",
            "    \"translation_en_to_ro\": {\n",
            "      \"early_stopping\": true,\n",
            "      \"max_length\": 300,\n",
            "      \"num_beams\": 4,\n",
            "      \"prefix\": \"translate English to Romanian: \"\n",
            "    }\n",
            "  },\n",
            "  \"tie_word_embeddings\": false,\n",
            "  \"transformers_version\": \"4.55.2\",\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 32128\n",
            "}\n",
            "\n",
            "tokenizer config file saved in google/flan-t5-base-peft-dialogue-summary-abdUllahsamir/checkpoint-5000/tokenizer_config.json\n",
            "Special tokens file saved in google/flan-t5-base-peft-dialogue-summary-abdUllahsamir/checkpoint-5000/special_tokens_map.json\n",
            "Copy vocab file to google/flan-t5-base-peft-dialogue-summary-abdUllahsamir/checkpoint-5000/spiece.model\n",
            "tokenizer config file saved in google/flan-t5-base-peft-dialogue-summary-abdUllahsamir/tokenizer_config.json\n",
            "Special tokens file saved in google/flan-t5-base-peft-dialogue-summary-abdUllahsamir/special_tokens_map.json\n",
            "Copy vocab file to google/flan-t5-base-peft-dialogue-summary-abdUllahsamir/spiece.model\n",
            "Saving model checkpoint to google/flan-t5-base-peft-dialogue-summary-abdUllahsamir/checkpoint-5500\n",
            "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--google--flan-t5-base/snapshots/7bcac572ce56db69c1ea7c8af255c5d7c9672fc2/config.json\n",
            "Model config T5Config {\n",
            "  \"architectures\": [\n",
            "    \"T5ForConditionalGeneration\"\n",
            "  ],\n",
            "  \"classifier_dropout\": 0.0,\n",
            "  \"d_ff\": 2048,\n",
            "  \"d_kv\": 64,\n",
            "  \"d_model\": 768,\n",
            "  \"decoder_start_token_id\": 0,\n",
            "  \"dense_act_fn\": \"gelu_new\",\n",
            "  \"dropout_rate\": 0.1,\n",
            "  \"eos_token_id\": 1,\n",
            "  \"feed_forward_proj\": \"gated-gelu\",\n",
            "  \"initializer_factor\": 1.0,\n",
            "  \"is_encoder_decoder\": true,\n",
            "  \"is_gated_act\": true,\n",
            "  \"layer_norm_epsilon\": 1e-06,\n",
            "  \"model_type\": \"t5\",\n",
            "  \"n_positions\": 512,\n",
            "  \"num_decoder_layers\": 12,\n",
            "  \"num_heads\": 12,\n",
            "  \"num_layers\": 12,\n",
            "  \"output_past\": true,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"relative_attention_max_distance\": 128,\n",
            "  \"relative_attention_num_buckets\": 32,\n",
            "  \"task_specific_params\": {\n",
            "    \"summarization\": {\n",
            "      \"early_stopping\": true,\n",
            "      \"length_penalty\": 2.0,\n",
            "      \"max_length\": 200,\n",
            "      \"min_length\": 30,\n",
            "      \"no_repeat_ngram_size\": 3,\n",
            "      \"num_beams\": 4,\n",
            "      \"prefix\": \"summarize: \"\n",
            "    },\n",
            "    \"translation_en_to_de\": {\n",
            "      \"early_stopping\": true,\n",
            "      \"max_length\": 300,\n",
            "      \"num_beams\": 4,\n",
            "      \"prefix\": \"translate English to German: \"\n",
            "    },\n",
            "    \"translation_en_to_fr\": {\n",
            "      \"early_stopping\": true,\n",
            "      \"max_length\": 300,\n",
            "      \"num_beams\": 4,\n",
            "      \"prefix\": \"translate English to French: \"\n",
            "    },\n",
            "    \"translation_en_to_ro\": {\n",
            "      \"early_stopping\": true,\n",
            "      \"max_length\": 300,\n",
            "      \"num_beams\": 4,\n",
            "      \"prefix\": \"translate English to Romanian: \"\n",
            "    }\n",
            "  },\n",
            "  \"tie_word_embeddings\": false,\n",
            "  \"transformers_version\": \"4.55.2\",\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 32128\n",
            "}\n",
            "\n",
            "tokenizer config file saved in google/flan-t5-base-peft-dialogue-summary-abdUllahsamir/checkpoint-5500/tokenizer_config.json\n",
            "Special tokens file saved in google/flan-t5-base-peft-dialogue-summary-abdUllahsamir/checkpoint-5500/special_tokens_map.json\n",
            "Copy vocab file to google/flan-t5-base-peft-dialogue-summary-abdUllahsamir/checkpoint-5500/spiece.model\n",
            "tokenizer config file saved in google/flan-t5-base-peft-dialogue-summary-abdUllahsamir/tokenizer_config.json\n",
            "Special tokens file saved in google/flan-t5-base-peft-dialogue-summary-abdUllahsamir/special_tokens_map.json\n",
            "Copy vocab file to google/flan-t5-base-peft-dialogue-summary-abdUllahsamir/spiece.model\n",
            "Saving model checkpoint to google/flan-t5-base-peft-dialogue-summary-abdUllahsamir/checkpoint-6000\n",
            "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--google--flan-t5-base/snapshots/7bcac572ce56db69c1ea7c8af255c5d7c9672fc2/config.json\n",
            "Model config T5Config {\n",
            "  \"architectures\": [\n",
            "    \"T5ForConditionalGeneration\"\n",
            "  ],\n",
            "  \"classifier_dropout\": 0.0,\n",
            "  \"d_ff\": 2048,\n",
            "  \"d_kv\": 64,\n",
            "  \"d_model\": 768,\n",
            "  \"decoder_start_token_id\": 0,\n",
            "  \"dense_act_fn\": \"gelu_new\",\n",
            "  \"dropout_rate\": 0.1,\n",
            "  \"eos_token_id\": 1,\n",
            "  \"feed_forward_proj\": \"gated-gelu\",\n",
            "  \"initializer_factor\": 1.0,\n",
            "  \"is_encoder_decoder\": true,\n",
            "  \"is_gated_act\": true,\n",
            "  \"layer_norm_epsilon\": 1e-06,\n",
            "  \"model_type\": \"t5\",\n",
            "  \"n_positions\": 512,\n",
            "  \"num_decoder_layers\": 12,\n",
            "  \"num_heads\": 12,\n",
            "  \"num_layers\": 12,\n",
            "  \"output_past\": true,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"relative_attention_max_distance\": 128,\n",
            "  \"relative_attention_num_buckets\": 32,\n",
            "  \"task_specific_params\": {\n",
            "    \"summarization\": {\n",
            "      \"early_stopping\": true,\n",
            "      \"length_penalty\": 2.0,\n",
            "      \"max_length\": 200,\n",
            "      \"min_length\": 30,\n",
            "      \"no_repeat_ngram_size\": 3,\n",
            "      \"num_beams\": 4,\n",
            "      \"prefix\": \"summarize: \"\n",
            "    },\n",
            "    \"translation_en_to_de\": {\n",
            "      \"early_stopping\": true,\n",
            "      \"max_length\": 300,\n",
            "      \"num_beams\": 4,\n",
            "      \"prefix\": \"translate English to German: \"\n",
            "    },\n",
            "    \"translation_en_to_fr\": {\n",
            "      \"early_stopping\": true,\n",
            "      \"max_length\": 300,\n",
            "      \"num_beams\": 4,\n",
            "      \"prefix\": \"translate English to French: \"\n",
            "    },\n",
            "    \"translation_en_to_ro\": {\n",
            "      \"early_stopping\": true,\n",
            "      \"max_length\": 300,\n",
            "      \"num_beams\": 4,\n",
            "      \"prefix\": \"translate English to Romanian: \"\n",
            "    }\n",
            "  },\n",
            "  \"tie_word_embeddings\": false,\n",
            "  \"transformers_version\": \"4.55.2\",\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 32128\n",
            "}\n",
            "\n",
            "tokenizer config file saved in google/flan-t5-base-peft-dialogue-summary-abdUllahsamir/checkpoint-6000/tokenizer_config.json\n",
            "Special tokens file saved in google/flan-t5-base-peft-dialogue-summary-abdUllahsamir/checkpoint-6000/special_tokens_map.json\n",
            "Copy vocab file to google/flan-t5-base-peft-dialogue-summary-abdUllahsamir/checkpoint-6000/spiece.model\n",
            "tokenizer config file saved in google/flan-t5-base-peft-dialogue-summary-abdUllahsamir/tokenizer_config.json\n",
            "Special tokens file saved in google/flan-t5-base-peft-dialogue-summary-abdUllahsamir/special_tokens_map.json\n",
            "Copy vocab file to google/flan-t5-base-peft-dialogue-summary-abdUllahsamir/spiece.model\n",
            "\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 500\n",
            "  Batch size = 2\n",
            "Saving model checkpoint to google/flan-t5-base-peft-dialogue-summary-abdUllahsamir/checkpoint-6500\n",
            "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--google--flan-t5-base/snapshots/7bcac572ce56db69c1ea7c8af255c5d7c9672fc2/config.json\n",
            "Model config T5Config {\n",
            "  \"architectures\": [\n",
            "    \"T5ForConditionalGeneration\"\n",
            "  ],\n",
            "  \"classifier_dropout\": 0.0,\n",
            "  \"d_ff\": 2048,\n",
            "  \"d_kv\": 64,\n",
            "  \"d_model\": 768,\n",
            "  \"decoder_start_token_id\": 0,\n",
            "  \"dense_act_fn\": \"gelu_new\",\n",
            "  \"dropout_rate\": 0.1,\n",
            "  \"eos_token_id\": 1,\n",
            "  \"feed_forward_proj\": \"gated-gelu\",\n",
            "  \"initializer_factor\": 1.0,\n",
            "  \"is_encoder_decoder\": true,\n",
            "  \"is_gated_act\": true,\n",
            "  \"layer_norm_epsilon\": 1e-06,\n",
            "  \"model_type\": \"t5\",\n",
            "  \"n_positions\": 512,\n",
            "  \"num_decoder_layers\": 12,\n",
            "  \"num_heads\": 12,\n",
            "  \"num_layers\": 12,\n",
            "  \"output_past\": true,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"relative_attention_max_distance\": 128,\n",
            "  \"relative_attention_num_buckets\": 32,\n",
            "  \"task_specific_params\": {\n",
            "    \"summarization\": {\n",
            "      \"early_stopping\": true,\n",
            "      \"length_penalty\": 2.0,\n",
            "      \"max_length\": 200,\n",
            "      \"min_length\": 30,\n",
            "      \"no_repeat_ngram_size\": 3,\n",
            "      \"num_beams\": 4,\n",
            "      \"prefix\": \"summarize: \"\n",
            "    },\n",
            "    \"translation_en_to_de\": {\n",
            "      \"early_stopping\": true,\n",
            "      \"max_length\": 300,\n",
            "      \"num_beams\": 4,\n",
            "      \"prefix\": \"translate English to German: \"\n",
            "    },\n",
            "    \"translation_en_to_fr\": {\n",
            "      \"early_stopping\": true,\n",
            "      \"max_length\": 300,\n",
            "      \"num_beams\": 4,\n",
            "      \"prefix\": \"translate English to French: \"\n",
            "    },\n",
            "    \"translation_en_to_ro\": {\n",
            "      \"early_stopping\": true,\n",
            "      \"max_length\": 300,\n",
            "      \"num_beams\": 4,\n",
            "      \"prefix\": \"translate English to Romanian: \"\n",
            "    }\n",
            "  },\n",
            "  \"tie_word_embeddings\": false,\n",
            "  \"transformers_version\": \"4.55.2\",\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 32128\n",
            "}\n",
            "\n",
            "tokenizer config file saved in google/flan-t5-base-peft-dialogue-summary-abdUllahsamir/checkpoint-6500/tokenizer_config.json\n",
            "Special tokens file saved in google/flan-t5-base-peft-dialogue-summary-abdUllahsamir/checkpoint-6500/special_tokens_map.json\n",
            "Copy vocab file to google/flan-t5-base-peft-dialogue-summary-abdUllahsamir/checkpoint-6500/spiece.model\n",
            "tokenizer config file saved in google/flan-t5-base-peft-dialogue-summary-abdUllahsamir/tokenizer_config.json\n",
            "Special tokens file saved in google/flan-t5-base-peft-dialogue-summary-abdUllahsamir/special_tokens_map.json\n",
            "Copy vocab file to google/flan-t5-base-peft-dialogue-summary-abdUllahsamir/spiece.model\n",
            "Saving model checkpoint to google/flan-t5-base-peft-dialogue-summary-abdUllahsamir/checkpoint-7000\n",
            "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--google--flan-t5-base/snapshots/7bcac572ce56db69c1ea7c8af255c5d7c9672fc2/config.json\n",
            "Model config T5Config {\n",
            "  \"architectures\": [\n",
            "    \"T5ForConditionalGeneration\"\n",
            "  ],\n",
            "  \"classifier_dropout\": 0.0,\n",
            "  \"d_ff\": 2048,\n",
            "  \"d_kv\": 64,\n",
            "  \"d_model\": 768,\n",
            "  \"decoder_start_token_id\": 0,\n",
            "  \"dense_act_fn\": \"gelu_new\",\n",
            "  \"dropout_rate\": 0.1,\n",
            "  \"eos_token_id\": 1,\n",
            "  \"feed_forward_proj\": \"gated-gelu\",\n",
            "  \"initializer_factor\": 1.0,\n",
            "  \"is_encoder_decoder\": true,\n",
            "  \"is_gated_act\": true,\n",
            "  \"layer_norm_epsilon\": 1e-06,\n",
            "  \"model_type\": \"t5\",\n",
            "  \"n_positions\": 512,\n",
            "  \"num_decoder_layers\": 12,\n",
            "  \"num_heads\": 12,\n",
            "  \"num_layers\": 12,\n",
            "  \"output_past\": true,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"relative_attention_max_distance\": 128,\n",
            "  \"relative_attention_num_buckets\": 32,\n",
            "  \"task_specific_params\": {\n",
            "    \"summarization\": {\n",
            "      \"early_stopping\": true,\n",
            "      \"length_penalty\": 2.0,\n",
            "      \"max_length\": 200,\n",
            "      \"min_length\": 30,\n",
            "      \"no_repeat_ngram_size\": 3,\n",
            "      \"num_beams\": 4,\n",
            "      \"prefix\": \"summarize: \"\n",
            "    },\n",
            "    \"translation_en_to_de\": {\n",
            "      \"early_stopping\": true,\n",
            "      \"max_length\": 300,\n",
            "      \"num_beams\": 4,\n",
            "      \"prefix\": \"translate English to German: \"\n",
            "    },\n",
            "    \"translation_en_to_fr\": {\n",
            "      \"early_stopping\": true,\n",
            "      \"max_length\": 300,\n",
            "      \"num_beams\": 4,\n",
            "      \"prefix\": \"translate English to French: \"\n",
            "    },\n",
            "    \"translation_en_to_ro\": {\n",
            "      \"early_stopping\": true,\n",
            "      \"max_length\": 300,\n",
            "      \"num_beams\": 4,\n",
            "      \"prefix\": \"translate English to Romanian: \"\n",
            "    }\n",
            "  },\n",
            "  \"tie_word_embeddings\": false,\n",
            "  \"transformers_version\": \"4.55.2\",\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 32128\n",
            "}\n",
            "\n",
            "tokenizer config file saved in google/flan-t5-base-peft-dialogue-summary-abdUllahsamir/checkpoint-7000/tokenizer_config.json\n",
            "Special tokens file saved in google/flan-t5-base-peft-dialogue-summary-abdUllahsamir/checkpoint-7000/special_tokens_map.json\n",
            "Copy vocab file to google/flan-t5-base-peft-dialogue-summary-abdUllahsamir/checkpoint-7000/spiece.model\n",
            "tokenizer config file saved in google/flan-t5-base-peft-dialogue-summary-abdUllahsamir/tokenizer_config.json\n",
            "Special tokens file saved in google/flan-t5-base-peft-dialogue-summary-abdUllahsamir/special_tokens_map.json\n",
            "Copy vocab file to google/flan-t5-base-peft-dialogue-summary-abdUllahsamir/spiece.model\n",
            "Saving model checkpoint to google/flan-t5-base-peft-dialogue-summary-abdUllahsamir/checkpoint-7500\n",
            "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--google--flan-t5-base/snapshots/7bcac572ce56db69c1ea7c8af255c5d7c9672fc2/config.json\n",
            "Model config T5Config {\n",
            "  \"architectures\": [\n",
            "    \"T5ForConditionalGeneration\"\n",
            "  ],\n",
            "  \"classifier_dropout\": 0.0,\n",
            "  \"d_ff\": 2048,\n",
            "  \"d_kv\": 64,\n",
            "  \"d_model\": 768,\n",
            "  \"decoder_start_token_id\": 0,\n",
            "  \"dense_act_fn\": \"gelu_new\",\n",
            "  \"dropout_rate\": 0.1,\n",
            "  \"eos_token_id\": 1,\n",
            "  \"feed_forward_proj\": \"gated-gelu\",\n",
            "  \"initializer_factor\": 1.0,\n",
            "  \"is_encoder_decoder\": true,\n",
            "  \"is_gated_act\": true,\n",
            "  \"layer_norm_epsilon\": 1e-06,\n",
            "  \"model_type\": \"t5\",\n",
            "  \"n_positions\": 512,\n",
            "  \"num_decoder_layers\": 12,\n",
            "  \"num_heads\": 12,\n",
            "  \"num_layers\": 12,\n",
            "  \"output_past\": true,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"relative_attention_max_distance\": 128,\n",
            "  \"relative_attention_num_buckets\": 32,\n",
            "  \"task_specific_params\": {\n",
            "    \"summarization\": {\n",
            "      \"early_stopping\": true,\n",
            "      \"length_penalty\": 2.0,\n",
            "      \"max_length\": 200,\n",
            "      \"min_length\": 30,\n",
            "      \"no_repeat_ngram_size\": 3,\n",
            "      \"num_beams\": 4,\n",
            "      \"prefix\": \"summarize: \"\n",
            "    },\n",
            "    \"translation_en_to_de\": {\n",
            "      \"early_stopping\": true,\n",
            "      \"max_length\": 300,\n",
            "      \"num_beams\": 4,\n",
            "      \"prefix\": \"translate English to German: \"\n",
            "    },\n",
            "    \"translation_en_to_fr\": {\n",
            "      \"early_stopping\": true,\n",
            "      \"max_length\": 300,\n",
            "      \"num_beams\": 4,\n",
            "      \"prefix\": \"translate English to French: \"\n",
            "    },\n",
            "    \"translation_en_to_ro\": {\n",
            "      \"early_stopping\": true,\n",
            "      \"max_length\": 300,\n",
            "      \"num_beams\": 4,\n",
            "      \"prefix\": \"translate English to Romanian: \"\n",
            "    }\n",
            "  },\n",
            "  \"tie_word_embeddings\": false,\n",
            "  \"transformers_version\": \"4.55.2\",\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 32128\n",
            "}\n",
            "\n",
            "tokenizer config file saved in google/flan-t5-base-peft-dialogue-summary-abdUllahsamir/checkpoint-7500/tokenizer_config.json\n",
            "Special tokens file saved in google/flan-t5-base-peft-dialogue-summary-abdUllahsamir/checkpoint-7500/special_tokens_map.json\n",
            "Copy vocab file to google/flan-t5-base-peft-dialogue-summary-abdUllahsamir/checkpoint-7500/spiece.model\n",
            "tokenizer config file saved in google/flan-t5-base-peft-dialogue-summary-abdUllahsamir/tokenizer_config.json\n",
            "Special tokens file saved in google/flan-t5-base-peft-dialogue-summary-abdUllahsamir/special_tokens_map.json\n",
            "Copy vocab file to google/flan-t5-base-peft-dialogue-summary-abdUllahsamir/spiece.model\n",
            "Saving model checkpoint to google/flan-t5-base-peft-dialogue-summary-abdUllahsamir/checkpoint-8000\n",
            "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--google--flan-t5-base/snapshots/7bcac572ce56db69c1ea7c8af255c5d7c9672fc2/config.json\n",
            "Model config T5Config {\n",
            "  \"architectures\": [\n",
            "    \"T5ForConditionalGeneration\"\n",
            "  ],\n",
            "  \"classifier_dropout\": 0.0,\n",
            "  \"d_ff\": 2048,\n",
            "  \"d_kv\": 64,\n",
            "  \"d_model\": 768,\n",
            "  \"decoder_start_token_id\": 0,\n",
            "  \"dense_act_fn\": \"gelu_new\",\n",
            "  \"dropout_rate\": 0.1,\n",
            "  \"eos_token_id\": 1,\n",
            "  \"feed_forward_proj\": \"gated-gelu\",\n",
            "  \"initializer_factor\": 1.0,\n",
            "  \"is_encoder_decoder\": true,\n",
            "  \"is_gated_act\": true,\n",
            "  \"layer_norm_epsilon\": 1e-06,\n",
            "  \"model_type\": \"t5\",\n",
            "  \"n_positions\": 512,\n",
            "  \"num_decoder_layers\": 12,\n",
            "  \"num_heads\": 12,\n",
            "  \"num_layers\": 12,\n",
            "  \"output_past\": true,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"relative_attention_max_distance\": 128,\n",
            "  \"relative_attention_num_buckets\": 32,\n",
            "  \"task_specific_params\": {\n",
            "    \"summarization\": {\n",
            "      \"early_stopping\": true,\n",
            "      \"length_penalty\": 2.0,\n",
            "      \"max_length\": 200,\n",
            "      \"min_length\": 30,\n",
            "      \"no_repeat_ngram_size\": 3,\n",
            "      \"num_beams\": 4,\n",
            "      \"prefix\": \"summarize: \"\n",
            "    },\n",
            "    \"translation_en_to_de\": {\n",
            "      \"early_stopping\": true,\n",
            "      \"max_length\": 300,\n",
            "      \"num_beams\": 4,\n",
            "      \"prefix\": \"translate English to German: \"\n",
            "    },\n",
            "    \"translation_en_to_fr\": {\n",
            "      \"early_stopping\": true,\n",
            "      \"max_length\": 300,\n",
            "      \"num_beams\": 4,\n",
            "      \"prefix\": \"translate English to French: \"\n",
            "    },\n",
            "    \"translation_en_to_ro\": {\n",
            "      \"early_stopping\": true,\n",
            "      \"max_length\": 300,\n",
            "      \"num_beams\": 4,\n",
            "      \"prefix\": \"translate English to Romanian: \"\n",
            "    }\n",
            "  },\n",
            "  \"tie_word_embeddings\": false,\n",
            "  \"transformers_version\": \"4.55.2\",\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 32128\n",
            "}\n",
            "\n",
            "tokenizer config file saved in google/flan-t5-base-peft-dialogue-summary-abdUllahsamir/checkpoint-8000/tokenizer_config.json\n",
            "Special tokens file saved in google/flan-t5-base-peft-dialogue-summary-abdUllahsamir/checkpoint-8000/special_tokens_map.json\n",
            "Copy vocab file to google/flan-t5-base-peft-dialogue-summary-abdUllahsamir/checkpoint-8000/spiece.model\n",
            "tokenizer config file saved in google/flan-t5-base-peft-dialogue-summary-abdUllahsamir/tokenizer_config.json\n",
            "Special tokens file saved in google/flan-t5-base-peft-dialogue-summary-abdUllahsamir/special_tokens_map.json\n",
            "Copy vocab file to google/flan-t5-base-peft-dialogue-summary-abdUllahsamir/spiece.model\n",
            "Saving model checkpoint to google/flan-t5-base-peft-dialogue-summary-abdUllahsamir/checkpoint-8500\n",
            "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--google--flan-t5-base/snapshots/7bcac572ce56db69c1ea7c8af255c5d7c9672fc2/config.json\n",
            "Model config T5Config {\n",
            "  \"architectures\": [\n",
            "    \"T5ForConditionalGeneration\"\n",
            "  ],\n",
            "  \"classifier_dropout\": 0.0,\n",
            "  \"d_ff\": 2048,\n",
            "  \"d_kv\": 64,\n",
            "  \"d_model\": 768,\n",
            "  \"decoder_start_token_id\": 0,\n",
            "  \"dense_act_fn\": \"gelu_new\",\n",
            "  \"dropout_rate\": 0.1,\n",
            "  \"eos_token_id\": 1,\n",
            "  \"feed_forward_proj\": \"gated-gelu\",\n",
            "  \"initializer_factor\": 1.0,\n",
            "  \"is_encoder_decoder\": true,\n",
            "  \"is_gated_act\": true,\n",
            "  \"layer_norm_epsilon\": 1e-06,\n",
            "  \"model_type\": \"t5\",\n",
            "  \"n_positions\": 512,\n",
            "  \"num_decoder_layers\": 12,\n",
            "  \"num_heads\": 12,\n",
            "  \"num_layers\": 12,\n",
            "  \"output_past\": true,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"relative_attention_max_distance\": 128,\n",
            "  \"relative_attention_num_buckets\": 32,\n",
            "  \"task_specific_params\": {\n",
            "    \"summarization\": {\n",
            "      \"early_stopping\": true,\n",
            "      \"length_penalty\": 2.0,\n",
            "      \"max_length\": 200,\n",
            "      \"min_length\": 30,\n",
            "      \"no_repeat_ngram_size\": 3,\n",
            "      \"num_beams\": 4,\n",
            "      \"prefix\": \"summarize: \"\n",
            "    },\n",
            "    \"translation_en_to_de\": {\n",
            "      \"early_stopping\": true,\n",
            "      \"max_length\": 300,\n",
            "      \"num_beams\": 4,\n",
            "      \"prefix\": \"translate English to German: \"\n",
            "    },\n",
            "    \"translation_en_to_fr\": {\n",
            "      \"early_stopping\": true,\n",
            "      \"max_length\": 300,\n",
            "      \"num_beams\": 4,\n",
            "      \"prefix\": \"translate English to French: \"\n",
            "    },\n",
            "    \"translation_en_to_ro\": {\n",
            "      \"early_stopping\": true,\n",
            "      \"max_length\": 300,\n",
            "      \"num_beams\": 4,\n",
            "      \"prefix\": \"translate English to Romanian: \"\n",
            "    }\n",
            "  },\n",
            "  \"tie_word_embeddings\": false,\n",
            "  \"transformers_version\": \"4.55.2\",\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 32128\n",
            "}\n",
            "\n",
            "tokenizer config file saved in google/flan-t5-base-peft-dialogue-summary-abdUllahsamir/checkpoint-8500/tokenizer_config.json\n",
            "Special tokens file saved in google/flan-t5-base-peft-dialogue-summary-abdUllahsamir/checkpoint-8500/special_tokens_map.json\n",
            "Copy vocab file to google/flan-t5-base-peft-dialogue-summary-abdUllahsamir/checkpoint-8500/spiece.model\n",
            "tokenizer config file saved in google/flan-t5-base-peft-dialogue-summary-abdUllahsamir/tokenizer_config.json\n",
            "Special tokens file saved in google/flan-t5-base-peft-dialogue-summary-abdUllahsamir/special_tokens_map.json\n",
            "Copy vocab file to google/flan-t5-base-peft-dialogue-summary-abdUllahsamir/spiece.model\n",
            "Saving model checkpoint to google/flan-t5-base-peft-dialogue-summary-abdUllahsamir/checkpoint-9000\n",
            "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--google--flan-t5-base/snapshots/7bcac572ce56db69c1ea7c8af255c5d7c9672fc2/config.json\n",
            "Model config T5Config {\n",
            "  \"architectures\": [\n",
            "    \"T5ForConditionalGeneration\"\n",
            "  ],\n",
            "  \"classifier_dropout\": 0.0,\n",
            "  \"d_ff\": 2048,\n",
            "  \"d_kv\": 64,\n",
            "  \"d_model\": 768,\n",
            "  \"decoder_start_token_id\": 0,\n",
            "  \"dense_act_fn\": \"gelu_new\",\n",
            "  \"dropout_rate\": 0.1,\n",
            "  \"eos_token_id\": 1,\n",
            "  \"feed_forward_proj\": \"gated-gelu\",\n",
            "  \"initializer_factor\": 1.0,\n",
            "  \"is_encoder_decoder\": true,\n",
            "  \"is_gated_act\": true,\n",
            "  \"layer_norm_epsilon\": 1e-06,\n",
            "  \"model_type\": \"t5\",\n",
            "  \"n_positions\": 512,\n",
            "  \"num_decoder_layers\": 12,\n",
            "  \"num_heads\": 12,\n",
            "  \"num_layers\": 12,\n",
            "  \"output_past\": true,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"relative_attention_max_distance\": 128,\n",
            "  \"relative_attention_num_buckets\": 32,\n",
            "  \"task_specific_params\": {\n",
            "    \"summarization\": {\n",
            "      \"early_stopping\": true,\n",
            "      \"length_penalty\": 2.0,\n",
            "      \"max_length\": 200,\n",
            "      \"min_length\": 30,\n",
            "      \"no_repeat_ngram_size\": 3,\n",
            "      \"num_beams\": 4,\n",
            "      \"prefix\": \"summarize: \"\n",
            "    },\n",
            "    \"translation_en_to_de\": {\n",
            "      \"early_stopping\": true,\n",
            "      \"max_length\": 300,\n",
            "      \"num_beams\": 4,\n",
            "      \"prefix\": \"translate English to German: \"\n",
            "    },\n",
            "    \"translation_en_to_fr\": {\n",
            "      \"early_stopping\": true,\n",
            "      \"max_length\": 300,\n",
            "      \"num_beams\": 4,\n",
            "      \"prefix\": \"translate English to French: \"\n",
            "    },\n",
            "    \"translation_en_to_ro\": {\n",
            "      \"early_stopping\": true,\n",
            "      \"max_length\": 300,\n",
            "      \"num_beams\": 4,\n",
            "      \"prefix\": \"translate English to Romanian: \"\n",
            "    }\n",
            "  },\n",
            "  \"tie_word_embeddings\": false,\n",
            "  \"transformers_version\": \"4.55.2\",\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 32128\n",
            "}\n",
            "\n",
            "tokenizer config file saved in google/flan-t5-base-peft-dialogue-summary-abdUllahsamir/checkpoint-9000/tokenizer_config.json\n",
            "Special tokens file saved in google/flan-t5-base-peft-dialogue-summary-abdUllahsamir/checkpoint-9000/special_tokens_map.json\n",
            "Copy vocab file to google/flan-t5-base-peft-dialogue-summary-abdUllahsamir/checkpoint-9000/spiece.model\n",
            "tokenizer config file saved in google/flan-t5-base-peft-dialogue-summary-abdUllahsamir/tokenizer_config.json\n",
            "Special tokens file saved in google/flan-t5-base-peft-dialogue-summary-abdUllahsamir/special_tokens_map.json\n",
            "Copy vocab file to google/flan-t5-base-peft-dialogue-summary-abdUllahsamir/spiece.model\n",
            "Saving model checkpoint to google/flan-t5-base-peft-dialogue-summary-abdUllahsamir/checkpoint-9500\n",
            "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--google--flan-t5-base/snapshots/7bcac572ce56db69c1ea7c8af255c5d7c9672fc2/config.json\n",
            "Model config T5Config {\n",
            "  \"architectures\": [\n",
            "    \"T5ForConditionalGeneration\"\n",
            "  ],\n",
            "  \"classifier_dropout\": 0.0,\n",
            "  \"d_ff\": 2048,\n",
            "  \"d_kv\": 64,\n",
            "  \"d_model\": 768,\n",
            "  \"decoder_start_token_id\": 0,\n",
            "  \"dense_act_fn\": \"gelu_new\",\n",
            "  \"dropout_rate\": 0.1,\n",
            "  \"eos_token_id\": 1,\n",
            "  \"feed_forward_proj\": \"gated-gelu\",\n",
            "  \"initializer_factor\": 1.0,\n",
            "  \"is_encoder_decoder\": true,\n",
            "  \"is_gated_act\": true,\n",
            "  \"layer_norm_epsilon\": 1e-06,\n",
            "  \"model_type\": \"t5\",\n",
            "  \"n_positions\": 512,\n",
            "  \"num_decoder_layers\": 12,\n",
            "  \"num_heads\": 12,\n",
            "  \"num_layers\": 12,\n",
            "  \"output_past\": true,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"relative_attention_max_distance\": 128,\n",
            "  \"relative_attention_num_buckets\": 32,\n",
            "  \"task_specific_params\": {\n",
            "    \"summarization\": {\n",
            "      \"early_stopping\": true,\n",
            "      \"length_penalty\": 2.0,\n",
            "      \"max_length\": 200,\n",
            "      \"min_length\": 30,\n",
            "      \"no_repeat_ngram_size\": 3,\n",
            "      \"num_beams\": 4,\n",
            "      \"prefix\": \"summarize: \"\n",
            "    },\n",
            "    \"translation_en_to_de\": {\n",
            "      \"early_stopping\": true,\n",
            "      \"max_length\": 300,\n",
            "      \"num_beams\": 4,\n",
            "      \"prefix\": \"translate English to German: \"\n",
            "    },\n",
            "    \"translation_en_to_fr\": {\n",
            "      \"early_stopping\": true,\n",
            "      \"max_length\": 300,\n",
            "      \"num_beams\": 4,\n",
            "      \"prefix\": \"translate English to French: \"\n",
            "    },\n",
            "    \"translation_en_to_ro\": {\n",
            "      \"early_stopping\": true,\n",
            "      \"max_length\": 300,\n",
            "      \"num_beams\": 4,\n",
            "      \"prefix\": \"translate English to Romanian: \"\n",
            "    }\n",
            "  },\n",
            "  \"tie_word_embeddings\": false,\n",
            "  \"transformers_version\": \"4.55.2\",\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 32128\n",
            "}\n",
            "\n",
            "tokenizer config file saved in google/flan-t5-base-peft-dialogue-summary-abdUllahsamir/checkpoint-9500/tokenizer_config.json\n",
            "Special tokens file saved in google/flan-t5-base-peft-dialogue-summary-abdUllahsamir/checkpoint-9500/special_tokens_map.json\n",
            "Copy vocab file to google/flan-t5-base-peft-dialogue-summary-abdUllahsamir/checkpoint-9500/spiece.model\n",
            "tokenizer config file saved in google/flan-t5-base-peft-dialogue-summary-abdUllahsamir/tokenizer_config.json\n",
            "Special tokens file saved in google/flan-t5-base-peft-dialogue-summary-abdUllahsamir/special_tokens_map.json\n",
            "Copy vocab file to google/flan-t5-base-peft-dialogue-summary-abdUllahsamir/spiece.model\n",
            "Saving model checkpoint to google/flan-t5-base-peft-dialogue-summary-abdUllahsamir/checkpoint-10000\n",
            "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--google--flan-t5-base/snapshots/7bcac572ce56db69c1ea7c8af255c5d7c9672fc2/config.json\n",
            "Model config T5Config {\n",
            "  \"architectures\": [\n",
            "    \"T5ForConditionalGeneration\"\n",
            "  ],\n",
            "  \"classifier_dropout\": 0.0,\n",
            "  \"d_ff\": 2048,\n",
            "  \"d_kv\": 64,\n",
            "  \"d_model\": 768,\n",
            "  \"decoder_start_token_id\": 0,\n",
            "  \"dense_act_fn\": \"gelu_new\",\n",
            "  \"dropout_rate\": 0.1,\n",
            "  \"eos_token_id\": 1,\n",
            "  \"feed_forward_proj\": \"gated-gelu\",\n",
            "  \"initializer_factor\": 1.0,\n",
            "  \"is_encoder_decoder\": true,\n",
            "  \"is_gated_act\": true,\n",
            "  \"layer_norm_epsilon\": 1e-06,\n",
            "  \"model_type\": \"t5\",\n",
            "  \"n_positions\": 512,\n",
            "  \"num_decoder_layers\": 12,\n",
            "  \"num_heads\": 12,\n",
            "  \"num_layers\": 12,\n",
            "  \"output_past\": true,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"relative_attention_max_distance\": 128,\n",
            "  \"relative_attention_num_buckets\": 32,\n",
            "  \"task_specific_params\": {\n",
            "    \"summarization\": {\n",
            "      \"early_stopping\": true,\n",
            "      \"length_penalty\": 2.0,\n",
            "      \"max_length\": 200,\n",
            "      \"min_length\": 30,\n",
            "      \"no_repeat_ngram_size\": 3,\n",
            "      \"num_beams\": 4,\n",
            "      \"prefix\": \"summarize: \"\n",
            "    },\n",
            "    \"translation_en_to_de\": {\n",
            "      \"early_stopping\": true,\n",
            "      \"max_length\": 300,\n",
            "      \"num_beams\": 4,\n",
            "      \"prefix\": \"translate English to German: \"\n",
            "    },\n",
            "    \"translation_en_to_fr\": {\n",
            "      \"early_stopping\": true,\n",
            "      \"max_length\": 300,\n",
            "      \"num_beams\": 4,\n",
            "      \"prefix\": \"translate English to French: \"\n",
            "    },\n",
            "    \"translation_en_to_ro\": {\n",
            "      \"early_stopping\": true,\n",
            "      \"max_length\": 300,\n",
            "      \"num_beams\": 4,\n",
            "      \"prefix\": \"translate English to Romanian: \"\n",
            "    }\n",
            "  },\n",
            "  \"tie_word_embeddings\": false,\n",
            "  \"transformers_version\": \"4.55.2\",\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 32128\n",
            "}\n",
            "\n",
            "tokenizer config file saved in google/flan-t5-base-peft-dialogue-summary-abdUllahsamir/checkpoint-10000/tokenizer_config.json\n",
            "Special tokens file saved in google/flan-t5-base-peft-dialogue-summary-abdUllahsamir/checkpoint-10000/special_tokens_map.json\n",
            "Copy vocab file to google/flan-t5-base-peft-dialogue-summary-abdUllahsamir/checkpoint-10000/spiece.model\n",
            "tokenizer config file saved in google/flan-t5-base-peft-dialogue-summary-abdUllahsamir/tokenizer_config.json\n",
            "Special tokens file saved in google/flan-t5-base-peft-dialogue-summary-abdUllahsamir/special_tokens_map.json\n",
            "Copy vocab file to google/flan-t5-base-peft-dialogue-summary-abdUllahsamir/spiece.model\n",
            "Saving model checkpoint to google/flan-t5-base-peft-dialogue-summary-abdUllahsamir/checkpoint-10500\n",
            "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--google--flan-t5-base/snapshots/7bcac572ce56db69c1ea7c8af255c5d7c9672fc2/config.json\n",
            "Model config T5Config {\n",
            "  \"architectures\": [\n",
            "    \"T5ForConditionalGeneration\"\n",
            "  ],\n",
            "  \"classifier_dropout\": 0.0,\n",
            "  \"d_ff\": 2048,\n",
            "  \"d_kv\": 64,\n",
            "  \"d_model\": 768,\n",
            "  \"decoder_start_token_id\": 0,\n",
            "  \"dense_act_fn\": \"gelu_new\",\n",
            "  \"dropout_rate\": 0.1,\n",
            "  \"eos_token_id\": 1,\n",
            "  \"feed_forward_proj\": \"gated-gelu\",\n",
            "  \"initializer_factor\": 1.0,\n",
            "  \"is_encoder_decoder\": true,\n",
            "  \"is_gated_act\": true,\n",
            "  \"layer_norm_epsilon\": 1e-06,\n",
            "  \"model_type\": \"t5\",\n",
            "  \"n_positions\": 512,\n",
            "  \"num_decoder_layers\": 12,\n",
            "  \"num_heads\": 12,\n",
            "  \"num_layers\": 12,\n",
            "  \"output_past\": true,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"relative_attention_max_distance\": 128,\n",
            "  \"relative_attention_num_buckets\": 32,\n",
            "  \"task_specific_params\": {\n",
            "    \"summarization\": {\n",
            "      \"early_stopping\": true,\n",
            "      \"length_penalty\": 2.0,\n",
            "      \"max_length\": 200,\n",
            "      \"min_length\": 30,\n",
            "      \"no_repeat_ngram_size\": 3,\n",
            "      \"num_beams\": 4,\n",
            "      \"prefix\": \"summarize: \"\n",
            "    },\n",
            "    \"translation_en_to_de\": {\n",
            "      \"early_stopping\": true,\n",
            "      \"max_length\": 300,\n",
            "      \"num_beams\": 4,\n",
            "      \"prefix\": \"translate English to German: \"\n",
            "    },\n",
            "    \"translation_en_to_fr\": {\n",
            "      \"early_stopping\": true,\n",
            "      \"max_length\": 300,\n",
            "      \"num_beams\": 4,\n",
            "      \"prefix\": \"translate English to French: \"\n",
            "    },\n",
            "    \"translation_en_to_ro\": {\n",
            "      \"early_stopping\": true,\n",
            "      \"max_length\": 300,\n",
            "      \"num_beams\": 4,\n",
            "      \"prefix\": \"translate English to Romanian: \"\n",
            "    }\n",
            "  },\n",
            "  \"tie_word_embeddings\": false,\n",
            "  \"transformers_version\": \"4.55.2\",\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 32128\n",
            "}\n",
            "\n",
            "tokenizer config file saved in google/flan-t5-base-peft-dialogue-summary-abdUllahsamir/checkpoint-10500/tokenizer_config.json\n",
            "Special tokens file saved in google/flan-t5-base-peft-dialogue-summary-abdUllahsamir/checkpoint-10500/special_tokens_map.json\n",
            "Copy vocab file to google/flan-t5-base-peft-dialogue-summary-abdUllahsamir/checkpoint-10500/spiece.model\n",
            "tokenizer config file saved in google/flan-t5-base-peft-dialogue-summary-abdUllahsamir/tokenizer_config.json\n",
            "Special tokens file saved in google/flan-t5-base-peft-dialogue-summary-abdUllahsamir/special_tokens_map.json\n",
            "Copy vocab file to google/flan-t5-base-peft-dialogue-summary-abdUllahsamir/spiece.model\n",
            "Saving model checkpoint to google/flan-t5-base-peft-dialogue-summary-abdUllahsamir/checkpoint-11000\n",
            "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--google--flan-t5-base/snapshots/7bcac572ce56db69c1ea7c8af255c5d7c9672fc2/config.json\n",
            "Model config T5Config {\n",
            "  \"architectures\": [\n",
            "    \"T5ForConditionalGeneration\"\n",
            "  ],\n",
            "  \"classifier_dropout\": 0.0,\n",
            "  \"d_ff\": 2048,\n",
            "  \"d_kv\": 64,\n",
            "  \"d_model\": 768,\n",
            "  \"decoder_start_token_id\": 0,\n",
            "  \"dense_act_fn\": \"gelu_new\",\n",
            "  \"dropout_rate\": 0.1,\n",
            "  \"eos_token_id\": 1,\n",
            "  \"feed_forward_proj\": \"gated-gelu\",\n",
            "  \"initializer_factor\": 1.0,\n",
            "  \"is_encoder_decoder\": true,\n",
            "  \"is_gated_act\": true,\n",
            "  \"layer_norm_epsilon\": 1e-06,\n",
            "  \"model_type\": \"t5\",\n",
            "  \"n_positions\": 512,\n",
            "  \"num_decoder_layers\": 12,\n",
            "  \"num_heads\": 12,\n",
            "  \"num_layers\": 12,\n",
            "  \"output_past\": true,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"relative_attention_max_distance\": 128,\n",
            "  \"relative_attention_num_buckets\": 32,\n",
            "  \"task_specific_params\": {\n",
            "    \"summarization\": {\n",
            "      \"early_stopping\": true,\n",
            "      \"length_penalty\": 2.0,\n",
            "      \"max_length\": 200,\n",
            "      \"min_length\": 30,\n",
            "      \"no_repeat_ngram_size\": 3,\n",
            "      \"num_beams\": 4,\n",
            "      \"prefix\": \"summarize: \"\n",
            "    },\n",
            "    \"translation_en_to_de\": {\n",
            "      \"early_stopping\": true,\n",
            "      \"max_length\": 300,\n",
            "      \"num_beams\": 4,\n",
            "      \"prefix\": \"translate English to German: \"\n",
            "    },\n",
            "    \"translation_en_to_fr\": {\n",
            "      \"early_stopping\": true,\n",
            "      \"max_length\": 300,\n",
            "      \"num_beams\": 4,\n",
            "      \"prefix\": \"translate English to French: \"\n",
            "    },\n",
            "    \"translation_en_to_ro\": {\n",
            "      \"early_stopping\": true,\n",
            "      \"max_length\": 300,\n",
            "      \"num_beams\": 4,\n",
            "      \"prefix\": \"translate English to Romanian: \"\n",
            "    }\n",
            "  },\n",
            "  \"tie_word_embeddings\": false,\n",
            "  \"transformers_version\": \"4.55.2\",\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 32128\n",
            "}\n",
            "\n",
            "tokenizer config file saved in google/flan-t5-base-peft-dialogue-summary-abdUllahsamir/checkpoint-11000/tokenizer_config.json\n",
            "Special tokens file saved in google/flan-t5-base-peft-dialogue-summary-abdUllahsamir/checkpoint-11000/special_tokens_map.json\n",
            "Copy vocab file to google/flan-t5-base-peft-dialogue-summary-abdUllahsamir/checkpoint-11000/spiece.model\n",
            "tokenizer config file saved in google/flan-t5-base-peft-dialogue-summary-abdUllahsamir/tokenizer_config.json\n",
            "Special tokens file saved in google/flan-t5-base-peft-dialogue-summary-abdUllahsamir/special_tokens_map.json\n",
            "Copy vocab file to google/flan-t5-base-peft-dialogue-summary-abdUllahsamir/spiece.model\n",
            "Saving model checkpoint to google/flan-t5-base-peft-dialogue-summary-abdUllahsamir/checkpoint-11500\n",
            "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--google--flan-t5-base/snapshots/7bcac572ce56db69c1ea7c8af255c5d7c9672fc2/config.json\n",
            "Model config T5Config {\n",
            "  \"architectures\": [\n",
            "    \"T5ForConditionalGeneration\"\n",
            "  ],\n",
            "  \"classifier_dropout\": 0.0,\n",
            "  \"d_ff\": 2048,\n",
            "  \"d_kv\": 64,\n",
            "  \"d_model\": 768,\n",
            "  \"decoder_start_token_id\": 0,\n",
            "  \"dense_act_fn\": \"gelu_new\",\n",
            "  \"dropout_rate\": 0.1,\n",
            "  \"eos_token_id\": 1,\n",
            "  \"feed_forward_proj\": \"gated-gelu\",\n",
            "  \"initializer_factor\": 1.0,\n",
            "  \"is_encoder_decoder\": true,\n",
            "  \"is_gated_act\": true,\n",
            "  \"layer_norm_epsilon\": 1e-06,\n",
            "  \"model_type\": \"t5\",\n",
            "  \"n_positions\": 512,\n",
            "  \"num_decoder_layers\": 12,\n",
            "  \"num_heads\": 12,\n",
            "  \"num_layers\": 12,\n",
            "  \"output_past\": true,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"relative_attention_max_distance\": 128,\n",
            "  \"relative_attention_num_buckets\": 32,\n",
            "  \"task_specific_params\": {\n",
            "    \"summarization\": {\n",
            "      \"early_stopping\": true,\n",
            "      \"length_penalty\": 2.0,\n",
            "      \"max_length\": 200,\n",
            "      \"min_length\": 30,\n",
            "      \"no_repeat_ngram_size\": 3,\n",
            "      \"num_beams\": 4,\n",
            "      \"prefix\": \"summarize: \"\n",
            "    },\n",
            "    \"translation_en_to_de\": {\n",
            "      \"early_stopping\": true,\n",
            "      \"max_length\": 300,\n",
            "      \"num_beams\": 4,\n",
            "      \"prefix\": \"translate English to German: \"\n",
            "    },\n",
            "    \"translation_en_to_fr\": {\n",
            "      \"early_stopping\": true,\n",
            "      \"max_length\": 300,\n",
            "      \"num_beams\": 4,\n",
            "      \"prefix\": \"translate English to French: \"\n",
            "    },\n",
            "    \"translation_en_to_ro\": {\n",
            "      \"early_stopping\": true,\n",
            "      \"max_length\": 300,\n",
            "      \"num_beams\": 4,\n",
            "      \"prefix\": \"translate English to Romanian: \"\n",
            "    }\n",
            "  },\n",
            "  \"tie_word_embeddings\": false,\n",
            "  \"transformers_version\": \"4.55.2\",\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 32128\n",
            "}\n",
            "\n",
            "tokenizer config file saved in google/flan-t5-base-peft-dialogue-summary-abdUllahsamir/checkpoint-11500/tokenizer_config.json\n",
            "Special tokens file saved in google/flan-t5-base-peft-dialogue-summary-abdUllahsamir/checkpoint-11500/special_tokens_map.json\n",
            "Copy vocab file to google/flan-t5-base-peft-dialogue-summary-abdUllahsamir/checkpoint-11500/spiece.model\n",
            "tokenizer config file saved in google/flan-t5-base-peft-dialogue-summary-abdUllahsamir/tokenizer_config.json\n",
            "Special tokens file saved in google/flan-t5-base-peft-dialogue-summary-abdUllahsamir/special_tokens_map.json\n",
            "Copy vocab file to google/flan-t5-base-peft-dialogue-summary-abdUllahsamir/spiece.model\n",
            "Saving model checkpoint to google/flan-t5-base-peft-dialogue-summary-abdUllahsamir/checkpoint-12000\n",
            "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--google--flan-t5-base/snapshots/7bcac572ce56db69c1ea7c8af255c5d7c9672fc2/config.json\n",
            "Model config T5Config {\n",
            "  \"architectures\": [\n",
            "    \"T5ForConditionalGeneration\"\n",
            "  ],\n",
            "  \"classifier_dropout\": 0.0,\n",
            "  \"d_ff\": 2048,\n",
            "  \"d_kv\": 64,\n",
            "  \"d_model\": 768,\n",
            "  \"decoder_start_token_id\": 0,\n",
            "  \"dense_act_fn\": \"gelu_new\",\n",
            "  \"dropout_rate\": 0.1,\n",
            "  \"eos_token_id\": 1,\n",
            "  \"feed_forward_proj\": \"gated-gelu\",\n",
            "  \"initializer_factor\": 1.0,\n",
            "  \"is_encoder_decoder\": true,\n",
            "  \"is_gated_act\": true,\n",
            "  \"layer_norm_epsilon\": 1e-06,\n",
            "  \"model_type\": \"t5\",\n",
            "  \"n_positions\": 512,\n",
            "  \"num_decoder_layers\": 12,\n",
            "  \"num_heads\": 12,\n",
            "  \"num_layers\": 12,\n",
            "  \"output_past\": true,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"relative_attention_max_distance\": 128,\n",
            "  \"relative_attention_num_buckets\": 32,\n",
            "  \"task_specific_params\": {\n",
            "    \"summarization\": {\n",
            "      \"early_stopping\": true,\n",
            "      \"length_penalty\": 2.0,\n",
            "      \"max_length\": 200,\n",
            "      \"min_length\": 30,\n",
            "      \"no_repeat_ngram_size\": 3,\n",
            "      \"num_beams\": 4,\n",
            "      \"prefix\": \"summarize: \"\n",
            "    },\n",
            "    \"translation_en_to_de\": {\n",
            "      \"early_stopping\": true,\n",
            "      \"max_length\": 300,\n",
            "      \"num_beams\": 4,\n",
            "      \"prefix\": \"translate English to German: \"\n",
            "    },\n",
            "    \"translation_en_to_fr\": {\n",
            "      \"early_stopping\": true,\n",
            "      \"max_length\": 300,\n",
            "      \"num_beams\": 4,\n",
            "      \"prefix\": \"translate English to French: \"\n",
            "    },\n",
            "    \"translation_en_to_ro\": {\n",
            "      \"early_stopping\": true,\n",
            "      \"max_length\": 300,\n",
            "      \"num_beams\": 4,\n",
            "      \"prefix\": \"translate English to Romanian: \"\n",
            "    }\n",
            "  },\n",
            "  \"tie_word_embeddings\": false,\n",
            "  \"transformers_version\": \"4.55.2\",\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 32128\n",
            "}\n",
            "\n",
            "tokenizer config file saved in google/flan-t5-base-peft-dialogue-summary-abdUllahsamir/checkpoint-12000/tokenizer_config.json\n",
            "Special tokens file saved in google/flan-t5-base-peft-dialogue-summary-abdUllahsamir/checkpoint-12000/special_tokens_map.json\n",
            "Copy vocab file to google/flan-t5-base-peft-dialogue-summary-abdUllahsamir/checkpoint-12000/spiece.model\n",
            "tokenizer config file saved in google/flan-t5-base-peft-dialogue-summary-abdUllahsamir/tokenizer_config.json\n",
            "Special tokens file saved in google/flan-t5-base-peft-dialogue-summary-abdUllahsamir/special_tokens_map.json\n",
            "Copy vocab file to google/flan-t5-base-peft-dialogue-summary-abdUllahsamir/spiece.model\n",
            "Saving model checkpoint to google/flan-t5-base-peft-dialogue-summary-abdUllahsamir/checkpoint-12460\n",
            "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--google--flan-t5-base/snapshots/7bcac572ce56db69c1ea7c8af255c5d7c9672fc2/config.json\n",
            "Model config T5Config {\n",
            "  \"architectures\": [\n",
            "    \"T5ForConditionalGeneration\"\n",
            "  ],\n",
            "  \"classifier_dropout\": 0.0,\n",
            "  \"d_ff\": 2048,\n",
            "  \"d_kv\": 64,\n",
            "  \"d_model\": 768,\n",
            "  \"decoder_start_token_id\": 0,\n",
            "  \"dense_act_fn\": \"gelu_new\",\n",
            "  \"dropout_rate\": 0.1,\n",
            "  \"eos_token_id\": 1,\n",
            "  \"feed_forward_proj\": \"gated-gelu\",\n",
            "  \"initializer_factor\": 1.0,\n",
            "  \"is_encoder_decoder\": true,\n",
            "  \"is_gated_act\": true,\n",
            "  \"layer_norm_epsilon\": 1e-06,\n",
            "  \"model_type\": \"t5\",\n",
            "  \"n_positions\": 512,\n",
            "  \"num_decoder_layers\": 12,\n",
            "  \"num_heads\": 12,\n",
            "  \"num_layers\": 12,\n",
            "  \"output_past\": true,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"relative_attention_max_distance\": 128,\n",
            "  \"relative_attention_num_buckets\": 32,\n",
            "  \"task_specific_params\": {\n",
            "    \"summarization\": {\n",
            "      \"early_stopping\": true,\n",
            "      \"length_penalty\": 2.0,\n",
            "      \"max_length\": 200,\n",
            "      \"min_length\": 30,\n",
            "      \"no_repeat_ngram_size\": 3,\n",
            "      \"num_beams\": 4,\n",
            "      \"prefix\": \"summarize: \"\n",
            "    },\n",
            "    \"translation_en_to_de\": {\n",
            "      \"early_stopping\": true,\n",
            "      \"max_length\": 300,\n",
            "      \"num_beams\": 4,\n",
            "      \"prefix\": \"translate English to German: \"\n",
            "    },\n",
            "    \"translation_en_to_fr\": {\n",
            "      \"early_stopping\": true,\n",
            "      \"max_length\": 300,\n",
            "      \"num_beams\": 4,\n",
            "      \"prefix\": \"translate English to French: \"\n",
            "    },\n",
            "    \"translation_en_to_ro\": {\n",
            "      \"early_stopping\": true,\n",
            "      \"max_length\": 300,\n",
            "      \"num_beams\": 4,\n",
            "      \"prefix\": \"translate English to Romanian: \"\n",
            "    }\n",
            "  },\n",
            "  \"tie_word_embeddings\": false,\n",
            "  \"transformers_version\": \"4.55.2\",\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 32128\n",
            "}\n",
            "\n",
            "tokenizer config file saved in google/flan-t5-base-peft-dialogue-summary-abdUllahsamir/checkpoint-12460/tokenizer_config.json\n",
            "Special tokens file saved in google/flan-t5-base-peft-dialogue-summary-abdUllahsamir/checkpoint-12460/special_tokens_map.json\n",
            "Copy vocab file to google/flan-t5-base-peft-dialogue-summary-abdUllahsamir/checkpoint-12460/spiece.model\n",
            "tokenizer config file saved in google/flan-t5-base-peft-dialogue-summary-abdUllahsamir/tokenizer_config.json\n",
            "Special tokens file saved in google/flan-t5-base-peft-dialogue-summary-abdUllahsamir/special_tokens_map.json\n",
            "Copy vocab file to google/flan-t5-base-peft-dialogue-summary-abdUllahsamir/spiece.model\n",
            "\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 500\n",
            "  Batch size = 2\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Training\n",
        "peft_trainer = Trainer(\n",
        "    model=peft_model,\n",
        "    args=peft_training_args,\n",
        "    train_dataset=tokenized_datasets['train'],\n",
        "    eval_dataset=tokenized_datasets['validation'],\n",
        "    tokenizer=tokenizer)\n",
        "\n",
        "peft_trainer.train();"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CxjqTV0UJjHX",
        "outputId": "ddea4f1b-a572-4d72-a9c5-a6e76e3a699a"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--google--flan-t5-base/snapshots/7bcac572ce56db69c1ea7c8af255c5d7c9672fc2/config.json\n",
            "Model config T5Config {\n",
            "  \"architectures\": [\n",
            "    \"T5ForConditionalGeneration\"\n",
            "  ],\n",
            "  \"classifier_dropout\": 0.0,\n",
            "  \"d_ff\": 2048,\n",
            "  \"d_kv\": 64,\n",
            "  \"d_model\": 768,\n",
            "  \"decoder_start_token_id\": 0,\n",
            "  \"dense_act_fn\": \"gelu_new\",\n",
            "  \"dropout_rate\": 0.1,\n",
            "  \"eos_token_id\": 1,\n",
            "  \"feed_forward_proj\": \"gated-gelu\",\n",
            "  \"initializer_factor\": 1.0,\n",
            "  \"is_encoder_decoder\": true,\n",
            "  \"is_gated_act\": true,\n",
            "  \"layer_norm_epsilon\": 1e-06,\n",
            "  \"model_type\": \"t5\",\n",
            "  \"n_positions\": 512,\n",
            "  \"num_decoder_layers\": 12,\n",
            "  \"num_heads\": 12,\n",
            "  \"num_layers\": 12,\n",
            "  \"output_past\": true,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"relative_attention_max_distance\": 128,\n",
            "  \"relative_attention_num_buckets\": 32,\n",
            "  \"task_specific_params\": {\n",
            "    \"summarization\": {\n",
            "      \"early_stopping\": true,\n",
            "      \"length_penalty\": 2.0,\n",
            "      \"max_length\": 200,\n",
            "      \"min_length\": 30,\n",
            "      \"no_repeat_ngram_size\": 3,\n",
            "      \"num_beams\": 4,\n",
            "      \"prefix\": \"summarize: \"\n",
            "    },\n",
            "    \"translation_en_to_de\": {\n",
            "      \"early_stopping\": true,\n",
            "      \"max_length\": 300,\n",
            "      \"num_beams\": 4,\n",
            "      \"prefix\": \"translate English to German: \"\n",
            "    },\n",
            "    \"translation_en_to_fr\": {\n",
            "      \"early_stopping\": true,\n",
            "      \"max_length\": 300,\n",
            "      \"num_beams\": 4,\n",
            "      \"prefix\": \"translate English to French: \"\n",
            "    },\n",
            "    \"translation_en_to_ro\": {\n",
            "      \"early_stopping\": true,\n",
            "      \"max_length\": 300,\n",
            "      \"num_beams\": 4,\n",
            "      \"prefix\": \"translate English to Romanian: \"\n",
            "    }\n",
            "  },\n",
            "  \"tie_word_embeddings\": false,\n",
            "  \"transformers_version\": \"4.55.2\",\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 32128\n",
            "}\n",
            "\n",
            "tokenizer config file saved in ./peft-dialogue-summary-ckpt/tokenizer_config.json\n",
            "Special tokens file saved in ./peft-dialogue-summary-ckpt/special_tokens_map.json\n",
            "Copy vocab file to ./peft-dialogue-summary-ckpt/spiece.model\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "('./peft-dialogue-summary-ckpt/tokenizer_config.json',\n",
              " './peft-dialogue-summary-ckpt/special_tokens_map.json',\n",
              " './peft-dialogue-summary-ckpt/spiece.model',\n",
              " './peft-dialogue-summary-ckpt/added_tokens.json',\n",
              " './peft-dialogue-summary-ckpt/tokenizer.json')"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Save the adapters\n",
        "peft_model_path = './peft-dialogue-summary-ckpt'\n",
        "peft_trainer.model.save_pretrained(peft_model_path)\n",
        "tokenizer.save_pretrained(peft_model_path)\n",
        "\n",
        "!zip -r peft-dialogue-summary-ckpt.zip peft-dialogue-summary-ckpt/\n",
        "files.download(\"peft-dialogue-summary-ckpt.zip\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "cd7f12abfb2746759b495a7ef91b3d68",
            "78171d4a4e2a485c92079ff91b20d878",
            "ff6648dedcc047f6af9af6b4156adc31",
            "bb079e7de9424f43a5f8c4e53ba09839",
            "64d55229cdcc45aaae7bb03c30e303ea",
            "6e2f5f4ce4f64158a39769f0b465402c",
            "3834e998717b4f6993764ac141d75b17",
            "34863901361344e88a2331a5e41fac08",
            "34b6a045ff6e452487a73d4939e247c3",
            "58914a4f12594fb799a7074d83c939cd",
            "d8af29cca0cd4ce98c9d05c02dd62672",
            "dc100abd6bab40f08c0648cebed742a7",
            "21fb24443f2c42089a80bd3a89ed3594",
            "a6ec47a379a04a17a90918b1a2611d52",
            "cd4a61f554644df3adecef4c7690a52c",
            "a98e38c61e314f41b8b12d70b67f8d6c",
            "7bb1c0e896e14a10a511e86d73ff861f",
            "cd3cb2f1faba4dbfb6a3a7da71d258fb",
            "8be8cc67674b4677952e2cd43a94174f",
            "02b5a681909a4b12bb8727d0bea9364b",
            "dcf5031c3c4b43968b4ff97f0c627734",
            "629d3bc7c0114dceab7a5630d1ea15ea",
            "85402d71e29e421ab50340c4751bf214",
            "1d457decbda14a688422a66f71dbbdfb",
            "888ddea2dbb343da90a42c06cbda1a02",
            "c31a9297bb1d431fa3883ce8bd19f465",
            "6c07d9f4f8004936bd64297b861be0a6",
            "a3a45eb4b670485a907e92ca2361e65a",
            "e482591e3dcf446e822cb601aa38edf9",
            "fd6f6ae3f7f2412a82fb608d78c4e904",
            "c50216e685874d2b85e7c5e2cdf037e3",
            "9ccff6243cf24861a4c7733c585c0ae9",
            "31dad2338d864c749d9f11ecba4ece73",
            "d63901a0f1ba47db9ce4feb59d6c53c8",
            "fe34afc8afec47ff8dbb40a921b6a79c",
            "bc5b29dc26de4f9286816cb15dd5ada9",
            "4270b1bf9b38438b96f79d6b7f4cb8bc",
            "8900edb94f334a4480d10c84438c443a",
            "4b6579f2b381430fa372aaf639c018ef",
            "194e05a7407049a397933121d30a9c25",
            "b383b3dfd3f5415a9ef2d172413f1ef4",
            "42929e29811141c2895988bedfe4c074",
            "53ffcc07dcab43e8b355382674e75a4f",
            "877c93cbaba4405ba3cc0eaa1a6463ef",
            "88de379a3d5c45ea8048ddfd3b4a34a7",
            "d4dc43ddd5f8468da41bf7e610c3a3a3",
            "1d325e862b834cd7930219cd5f6f58d3",
            "117babb24a6b4ea18d676a859fe16425",
            "2b04f17460d74cfcb8dbd387457ecbc0",
            "d2e9da1d5e11447398cf15d17e6efd2e",
            "748af1c3c30b4d5fa0ecdb92f0b42f2b",
            "0bff63cd37cc4dc0810bb94f2f3bd287",
            "6e84b95ce5ff4669b1012d13ae51b881",
            "73e61a7e81c94535af87afb1c03f8d6b",
            "296a0cf3c9cb4fb7b11218307423dd6f"
          ]
        },
        "id": "zET_fW5fOA-1",
        "outputId": "f0e64bf2-6774-4b97-ee95-23380de776b4"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Saving model checkpoint to google/flan-t5-base-peft-dialogue-summary-abdUllahsamir\n",
            "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--google--flan-t5-base/snapshots/7bcac572ce56db69c1ea7c8af255c5d7c9672fc2/config.json\n",
            "Model config T5Config {\n",
            "  \"architectures\": [\n",
            "    \"T5ForConditionalGeneration\"\n",
            "  ],\n",
            "  \"classifier_dropout\": 0.0,\n",
            "  \"d_ff\": 2048,\n",
            "  \"d_kv\": 64,\n",
            "  \"d_model\": 768,\n",
            "  \"decoder_start_token_id\": 0,\n",
            "  \"dense_act_fn\": \"gelu_new\",\n",
            "  \"dropout_rate\": 0.1,\n",
            "  \"eos_token_id\": 1,\n",
            "  \"feed_forward_proj\": \"gated-gelu\",\n",
            "  \"initializer_factor\": 1.0,\n",
            "  \"is_encoder_decoder\": true,\n",
            "  \"is_gated_act\": true,\n",
            "  \"layer_norm_epsilon\": 1e-06,\n",
            "  \"model_type\": \"t5\",\n",
            "  \"n_positions\": 512,\n",
            "  \"num_decoder_layers\": 12,\n",
            "  \"num_heads\": 12,\n",
            "  \"num_layers\": 12,\n",
            "  \"output_past\": true,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"relative_attention_max_distance\": 128,\n",
            "  \"relative_attention_num_buckets\": 32,\n",
            "  \"task_specific_params\": {\n",
            "    \"summarization\": {\n",
            "      \"early_stopping\": true,\n",
            "      \"length_penalty\": 2.0,\n",
            "      \"max_length\": 200,\n",
            "      \"min_length\": 30,\n",
            "      \"no_repeat_ngram_size\": 3,\n",
            "      \"num_beams\": 4,\n",
            "      \"prefix\": \"summarize: \"\n",
            "    },\n",
            "    \"translation_en_to_de\": {\n",
            "      \"early_stopping\": true,\n",
            "      \"max_length\": 300,\n",
            "      \"num_beams\": 4,\n",
            "      \"prefix\": \"translate English to German: \"\n",
            "    },\n",
            "    \"translation_en_to_fr\": {\n",
            "      \"early_stopping\": true,\n",
            "      \"max_length\": 300,\n",
            "      \"num_beams\": 4,\n",
            "      \"prefix\": \"translate English to French: \"\n",
            "    },\n",
            "    \"translation_en_to_ro\": {\n",
            "      \"early_stopping\": true,\n",
            "      \"max_length\": 300,\n",
            "      \"num_beams\": 4,\n",
            "      \"prefix\": \"translate English to Romanian: \"\n",
            "    }\n",
            "  },\n",
            "  \"tie_word_embeddings\": false,\n",
            "  \"transformers_version\": \"4.55.2\",\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 32128\n",
            "}\n",
            "\n",
            "tokenizer config file saved in google/flan-t5-base-peft-dialogue-summary-abdUllahsamir/tokenizer_config.json\n",
            "Special tokens file saved in google/flan-t5-base-peft-dialogue-summary-abdUllahsamir/special_tokens_map.json\n",
            "Copy vocab file to google/flan-t5-base-peft-dialogue-summary-abdUllahsamir/spiece.model\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "cd7f12abfb2746759b495a7ef91b3d68",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Processing Files (0 / 0)                : |          |  0.00B /  0.00B            "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "dc100abd6bab40f08c0648cebed742a7",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "New Data Upload                         : |          |  0.00B /  0.00B            "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "85402d71e29e421ab50340c4751bf214",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  ...ary-abdUllahsamir/training_args.bin: 100%|##########| 5.37kB / 5.37kB            "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d63901a0f1ba47db9ce4feb59d6c53c8",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  ...-summary-abdUllahsamir/spiece.model: 100%|##########|  792kB /  792kB            "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "88de379a3d5c45ea8048ddfd3b4a34a7",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  ...llahsamir/adapter_model.safetensors: 100%|##########| 17.7MB / 17.7MB            "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "CommitInfo(commit_url='https://huggingface.co/abdullahzahran/flan-t5-base-peft-dialogue-summary-abdUllahsamir/commit/c6a6efe92d7c6a62901acbbda824099a5956cf16', commit_message='Training Complete', commit_description='', oid='c6a6efe92d7c6a62901acbbda824099a5956cf16', pr_url=None, repo_url=RepoUrl('https://huggingface.co/abdullahzahran/flan-t5-base-peft-dialogue-summary-abdUllahsamir', endpoint='https://huggingface.co', repo_type='model', repo_id='abdullahzahran/flan-t5-base-peft-dialogue-summary-abdUllahsamir'), pr_revision=None, pr_num=None)"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Finally, Saving and sharing adapters\n",
        "peft_trainer.push_to_hub(commit_message='Training Complete')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OSiMEf65NC0f"
      },
      "source": [
        "----"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GduBCjkL5-Cz"
      },
      "source": [
        "### Inference"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "iq6bSa7eInSX"
      },
      "outputs": [],
      "source": [
        "from peft import PeftModel\n",
        "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n",
        "import torch\n",
        "from pprint import pprint"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aeP7pXaKMMkl",
        "outputId": "371eec6c-bc80-406a-fc24-7be7fc416fcc"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "loading file spiece.model from cache at /root/.cache/huggingface/hub/models--google--flan-t5-base/snapshots/7bcac572ce56db69c1ea7c8af255c5d7c9672fc2/spiece.model\n",
            "loading file tokenizer.json from cache at /root/.cache/huggingface/hub/models--google--flan-t5-base/snapshots/7bcac572ce56db69c1ea7c8af255c5d7c9672fc2/tokenizer.json\n",
            "loading file added_tokens.json from cache at None\n",
            "loading file special_tokens_map.json from cache at /root/.cache/huggingface/hub/models--google--flan-t5-base/snapshots/7bcac572ce56db69c1ea7c8af255c5d7c9672fc2/special_tokens_map.json\n",
            "loading file tokenizer_config.json from cache at /root/.cache/huggingface/hub/models--google--flan-t5-base/snapshots/7bcac572ce56db69c1ea7c8af255c5d7c9672fc2/tokenizer_config.json\n",
            "loading file chat_template.jinja from cache at None\n",
            "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--google--flan-t5-base/snapshots/7bcac572ce56db69c1ea7c8af255c5d7c9672fc2/config.json\n",
            "Model config T5Config {\n",
            "  \"architectures\": [\n",
            "    \"T5ForConditionalGeneration\"\n",
            "  ],\n",
            "  \"classifier_dropout\": 0.0,\n",
            "  \"d_ff\": 2048,\n",
            "  \"d_kv\": 64,\n",
            "  \"d_model\": 768,\n",
            "  \"decoder_start_token_id\": 0,\n",
            "  \"dense_act_fn\": \"gelu_new\",\n",
            "  \"dropout_rate\": 0.1,\n",
            "  \"eos_token_id\": 1,\n",
            "  \"feed_forward_proj\": \"gated-gelu\",\n",
            "  \"initializer_factor\": 1.0,\n",
            "  \"is_encoder_decoder\": true,\n",
            "  \"is_gated_act\": true,\n",
            "  \"layer_norm_epsilon\": 1e-06,\n",
            "  \"model_type\": \"t5\",\n",
            "  \"n_positions\": 512,\n",
            "  \"num_decoder_layers\": 12,\n",
            "  \"num_heads\": 12,\n",
            "  \"num_layers\": 12,\n",
            "  \"output_past\": true,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"relative_attention_max_distance\": 128,\n",
            "  \"relative_attention_num_buckets\": 32,\n",
            "  \"task_specific_params\": {\n",
            "    \"summarization\": {\n",
            "      \"early_stopping\": true,\n",
            "      \"length_penalty\": 2.0,\n",
            "      \"max_length\": 200,\n",
            "      \"min_length\": 30,\n",
            "      \"no_repeat_ngram_size\": 3,\n",
            "      \"num_beams\": 4,\n",
            "      \"prefix\": \"summarize: \"\n",
            "    },\n",
            "    \"translation_en_to_de\": {\n",
            "      \"early_stopping\": true,\n",
            "      \"max_length\": 300,\n",
            "      \"num_beams\": 4,\n",
            "      \"prefix\": \"translate English to German: \"\n",
            "    },\n",
            "    \"translation_en_to_fr\": {\n",
            "      \"early_stopping\": true,\n",
            "      \"max_length\": 300,\n",
            "      \"num_beams\": 4,\n",
            "      \"prefix\": \"translate English to French: \"\n",
            "    },\n",
            "    \"translation_en_to_ro\": {\n",
            "      \"early_stopping\": true,\n",
            "      \"max_length\": 300,\n",
            "      \"num_beams\": 4,\n",
            "      \"prefix\": \"translate English to Romanian: \"\n",
            "    }\n",
            "  },\n",
            "  \"tie_word_embeddings\": false,\n",
            "  \"torch_dtype\": \"bfloat16\",\n",
            "  \"transformers_version\": \"4.55.2\",\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 32128\n",
            "}\n",
            "\n",
            "loading weights file model.safetensors from cache at /root/.cache/huggingface/hub/models--google--flan-t5-base/snapshots/7bcac572ce56db69c1ea7c8af255c5d7c9672fc2/model.safetensors\n",
            "Instantiating T5ForConditionalGeneration model under default dtype torch.bfloat16.\n",
            "Generate config GenerationConfig {\n",
            "  \"decoder_start_token_id\": 0,\n",
            "  \"eos_token_id\": 1,\n",
            "  \"pad_token_id\": 0\n",
            "}\n",
            "\n",
            "All model checkpoint weights were used when initializing T5ForConditionalGeneration.\n",
            "\n",
            "All the weights of T5ForConditionalGeneration were initialized from the model checkpoint at google/flan-t5-base.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use T5ForConditionalGeneration for predictions without further training.\n",
            "loading configuration file generation_config.json from cache at /root/.cache/huggingface/hub/models--google--flan-t5-base/snapshots/7bcac572ce56db69c1ea7c8af255c5d7c9672fc2/generation_config.json\n",
            "Generate config GenerationConfig {\n",
            "  \"decoder_start_token_id\": 0,\n",
            "  \"eos_token_id\": 1,\n",
            "  \"pad_token_id\": 0\n",
            "}\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Define the checkpoints\n",
        "base_model_ckpt = \"google/flan-t5-base\"\n",
        "peft_model_ckpt = \"google/flan-t5-base-peft-dialogue-summary-abdUllahsamir\"\n",
        "\n",
        "# Load the tokenizer and base model\n",
        "tokenizer = AutoTokenizer.from_pretrained(base_model_ckpt)\n",
        "base_model = AutoModelForSeq2SeqLM.from_pretrained(base_model_ckpt, torch_dtype=torch.bfloat16)\n",
        "\n",
        "# Load the PEFT model\n",
        "peft_model = PeftModel.from_pretrained(base_model,\n",
        "                                       peft_model_ckpt,\n",
        "                                       torch_dtype=torch.bfloat16,\n",
        "                                       is_trainable=False)  # only for inference"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y9mB4dKENH-K"
      },
      "source": [
        "### Testing on Some Samples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UOGKI8qENJKs",
        "outputId": "a130eadb-f1a3-4f04-fe13-2a5fb24b6c33"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DIALOGUE:\n",
            "('#Person1#: Have you considered upgrading your system?\\n'\n",
            " \"#Person2#: Yes, but I'm not sure what exactly I would need.\\n\"\n",
            " '#Person1#: You could consider adding a painting program to your software. It '\n",
            " 'would allow you to make up your own flyers and banners for advertising.\\n'\n",
            " '#Person2#: That would be a definite bonus.\\n'\n",
            " '#Person1#: You might also want to upgrade your hardware because it is pretty '\n",
            " 'outdated now.\\n'\n",
            " '#Person2#: How can we do that?\\n'\n",
            " \"#Person1#: You'd probably need a faster processor, to begin with. And you \"\n",
            " 'also need a more powerful hard disc, more memory and a faster modem. Do you '\n",
            " 'have a CD-ROM drive?\\n'\n",
            " '#Person2#: No.\\n'\n",
            " '#Person1#: Then you might want to add a CD-ROM drive too, because most new '\n",
            " 'software programs are coming out on Cds.\\n'\n",
            " '#Person2#: That sounds great. Thanks.')\n",
            "\n",
            "BASELINE HUMAN SUMMARY:\n",
            "('#Person1# teaches #Person2# how to upgrade software and hardware in '\n",
            " \"#Person2#'s system.\")\n",
            "\n",
            "PEFT MODEL:\n",
            "('#Person2# suggests adding a painting program to the software. #Person1# '\n",
            " 'suggests adding a CD-ROM drive and a CD-ROM drive.')\n"
          ]
        }
      ],
      "source": [
        "# an example\n",
        "dialogue = dataset['test'][200]['dialogue']\n",
        "baseline_human_summary = dataset['test'][200]['summary']\n",
        "\n",
        "# Full prompt\n",
        "prompt = f\"\"\"\n",
        "Summarize the following conversation.\n",
        "\n",
        "{dialogue}\n",
        "\n",
        "Summary: \"\"\"\n",
        "\n",
        "# tokenizing\n",
        "input_ids = tokenizer(prompt, return_tensors=\"pt\").input_ids\n",
        "\n",
        "# PEFT model inference\n",
        "peft_model_outputs = peft_model.generate(input_ids=input_ids,\n",
        "                                         generation_config=GenerationConfig(max_new_tokens=200, num_beams=1))\n",
        "peft_model_text_output = tokenizer.decode(peft_model_outputs[0], skip_special_tokens=True)\n",
        "\n",
        "# Dialogue & Output\n",
        "print(\"DIALOGUE:\")\n",
        "pprint(dialogue)\n",
        "print()\n",
        "\n",
        "print(\"BASELINE HUMAN SUMMARY:\")\n",
        "pprint(baseline_human_summary)\n",
        "print()\n",
        "\n",
        "print(\"PEFT MODEL:\")\n",
        "pprint(peft_model_text_output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 103,
          "referenced_widgets": [
            "63540f595cfc476fb4d098aaad8c6d85",
            "c42929f9661b42f38fdb92efc02f1dc2",
            "402867af1b2246adbc87ac97ad9afdbc",
            "68d71b15632c44ddb11a8a55f77ebe83",
            "413ea008f7654b56a8381672a513e378",
            "149f2dd04bfa4f749312810454072f88",
            "71a72bcb933b4a7db0e51070ff627fe5",
            "b7b15ae205fb4d64ad1770e8cb4e3a90",
            "765b1a17804d414589adaa7e5a452573",
            "6aa598a1c1e04fb6bd0186a377d10982",
            "4e4c14819db64a65b292e676dc55cd8e"
          ]
        },
        "id": "mPWq1uCZOeJ3",
        "outputId": "228cfa4b-c682-4a47-f9c1-f8eb69c0c317"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "63540f595cfc476fb4d098aaad8c6d85",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading builder script: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ROUGE-1 F1: 0.2941\n",
            "ROUGE-2 F1: 0.0000\n",
            "ROUGE-L F1: 0.2353\n"
          ]
        }
      ],
      "source": [
        "# Load the ROUGE metric\n",
        "rouge = load(\"rouge\")\n",
        "\n",
        "# ROUGE-L --> Longest Common Subsequence\n",
        "\n",
        "# Calculate ROUGE scores\n",
        "scores = rouge.compute(predictions=[peft_model_text_output], references=[baseline_human_summary])\n",
        "\n",
        "# Print the ROUGE scores\n",
        "print(f\"ROUGE-1 F1: {scores['rouge1']:.4f}\")\n",
        "print(f\"ROUGE-2 F1: {scores['rouge2']:.4f}\")\n",
        "print(f\"ROUGE-L F1: {scores['rougeL']:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ywHXuHghZVhP"
      },
      "source": [
        "----"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}